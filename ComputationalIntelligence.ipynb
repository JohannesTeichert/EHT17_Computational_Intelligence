{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Journal\n",
    "\n",
    "## Lection 1 - 08. Mar. 2018, Evolutionary Computation\n",
    "\n",
    "What is evolutionary computing:\n",
    "https://en.wikipedia.org/wiki/Evolutionary_computation\n",
    "\n",
    "Confidence -> p. values, C-Intervals\n",
    "\n",
    "Computational intelligence emerged out of big data.\n",
    "\n",
    "Heuristic algorithm: cant always give solution, if solution you dont know if it is useable or correct\n",
    "\n",
    "Computational Intelligence vs AI:\n",
    "\n",
    "Both fall under maschine learning\n",
    "\n",
    "AI -> hard computing -> always the same algorithm -> like a monkey \n",
    "CI -> soft computing (soft boundaries, fuzzy logic(next semester)) -> very adaptive -> more complex -> makes it heuristic\n",
    "\n",
    "Clinical Trial, Beta Roll out, tweaking, market.\n",
    "\n",
    "Patient in the ICU -> artificial breathing -> wening (research that) -> liung machine gradually needs to lower its power so the lungs start breathing themselves again.\n",
    "\n",
    "MYCT->Processsor Speed\n",
    "\n",
    "## 1. Styles of learning\n",
    "\n",
    "Classification:\n",
    "100 records, 80 records used to trained the classifier ()training set, this classifier is tested against the remaining 20 (test set).\n",
    "\n",
    "\n",
    "Association:\n",
    "combining classifiers\n",
    "\n",
    "\n",
    "## Attributes\n",
    "\n",
    "\n",
    "\n",
    "## I/O Problems\n",
    "\n",
    "Choose Appropriate architectures -> disadvantages: you dont know if the other algo would have worked\n",
    "\n",
    "Convert input -> disadvantages: accuracy of data gets lost and conversion rules need to be made\n",
    "\n",
    "\n",
    "## Conversion\n",
    "\n",
    "Hamming Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Execrise:\n",
    "\n",
    "I decided to use Jupyter Lab which is a self hosted development web ui for scientific note taking and data visualization. It is based on the open source project jupyter notebook also known as ipython shell.\n",
    "\n",
    "Besides python it supports multiple kernels which can be installed as you need them.\n",
    "\n",
    "For this learning journal I installed iRkernel to solve the R execises.\n",
    "\n",
    "Jupyter Lab feels like a traditional IDE with multiple configurable panels and splitable views.\n",
    "\n",
    "You have a file tree on the left, the main code panel for the notebook on the right. The Notebook itself consists of cells which can also have different kernels active. This enables to use Markdown in one cell and R in the next one. Markdown and raw text interpretation are shipped by default.\n",
    "\n",
    "https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html\n",
    "\n",
    "\n",
    "After installing Jupyter Lab and trying the first execise with rweka i had to run ```sudo R CMD javareconf``` and add some jvm shared libraries to the `LD_LIBRARY_PATH`\n",
    "\n",
    "This might also only have been necessary because the linux distribution I am running.\n",
    "\n",
    "--------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t8124 obs. of  23 variables:\n",
      " $ type                    : Factor w/ 2 levels \"edible\",\"poisonous\": 2 1 1 2 1 1 1 1 2 1 ...\n",
      " $ cap_shape               : Factor w/ 6 levels \"bell\",\"conical\",..: 3 3 1 3 3 3 1 1 3 1 ...\n",
      " $ cap_surface             : Factor w/ 4 levels \"fibrous\",\"grooves\",..: 4 4 4 3 4 3 4 3 3 4 ...\n",
      " $ cap_color               : Factor w/ 10 levels \"brown\",\"buff\",..: 1 10 9 9 4 10 9 9 9 10 ...\n",
      " $ bruises                 : Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 1 2 2 2 2 2 ...\n",
      " $ odor                    : Factor w/ 9 levels \"almond\",\"anise\",..: 8 1 2 8 7 1 1 2 8 1 ...\n",
      " $ gill_attachment         : Factor w/ 2 levels \"attached\",\"free\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ gill_spacing            : Factor w/ 2 levels \"close\",\"crowded\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " $ gill_size               : Factor w/ 2 levels \"broad\",\"narrow\": 2 1 1 2 1 1 1 1 2 1 ...\n",
      " $ gill_color              : Factor w/ 12 levels \"black\",\"brown\",..: 1 1 2 2 1 2 5 2 8 5 ...\n",
      " $ stalk_shape             : Factor w/ 2 levels \"enlarging\",\"tapering\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " $ stalk_root              : Factor w/ 5 levels \"bulbous\",\"club\",..: 3 2 2 3 3 2 2 2 3 2 ...\n",
      " $ stalk_surface_above_ring: Factor w/ 4 levels \"fibrous\",\"scaly\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " $ stalk_surface_below_ring: Factor w/ 4 levels \"fibrous\",\"scaly\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " $ stalk_color_above_ring  : Factor w/ 9 levels \"brown\",\"buff\",..: 8 8 8 8 8 8 8 8 8 8 ...\n",
      " $ stalk_color_below_ring  : Factor w/ 9 levels \"brown\",\"buff\",..: 8 8 8 8 8 8 8 8 8 8 ...\n",
      " $ veil_type               : Factor w/ 1 level \"partial\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ veil_color              : Factor w/ 4 levels \"brown\",\"orange\",..: 3 3 3 3 3 3 3 3 3 3 ...\n",
      " $ ring_number             : Factor w/ 3 levels \"none\",\"one\",\"two\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ ring_type               : Factor w/ 5 levels \"evanescent\",\"flaring\",..: 5 5 5 5 1 5 5 5 5 5 ...\n",
      " $ spore_print_color       : Factor w/ 9 levels \"black\",\"brown\",..: 1 2 2 1 2 1 1 2 1 1 ...\n",
      " $ population              : Factor w/ 6 levels \"abundant\",\"clustered\",..: 4 3 3 4 1 3 3 4 5 4 ...\n",
      " $ habitat                 : Factor w/ 7 levels \"grasses\",\"leaves\",..: 5 1 3 5 1 1 3 3 1 3 ...\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"RWeka\")\n",
    "\n",
    "library(RWeka)\n",
    "\n",
    "#Assignment 1\n",
    "mushrooms <- read.csv(\"mushrooms.csv\", stringsAsFactors = TRUE)\n",
    "\n",
    "str(mushrooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1:\n",
    "\n",
    "### Take a look at the database, and describe it in your learning journal\n",
    "\n",
    "Dataset has 23 variables with 2-12 levels. \n",
    "\n",
    "The variables describe the appearance and behaviour of the mushrooms. \n",
    "\n",
    "\"Type\" for example has to levels -> edible and poisonous while cap color is much more granulous with 10 distinguished colors for the cap of the mushroom.\n",
    "\n",
    "The variables describe the appearance, behaviour, odor, spatial distribution and so on.\n",
    "\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "\n",
    "### use the str() command on all 23 variables. Do you notice anything unusual?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Factor w/ 2 levels \"edible\",\"poisonous\": 2 1 1 2 1 1 1 1 2 1 ...\n",
      " Factor w/ 6 levels \"bell\",\"conical\",..: 3 3 1 3 3 3 1 1 3 1 ...\n",
      " Factor w/ 4 levels \"fibrous\",\"grooves\",..: 4 4 4 3 4 3 4 3 3 4 ...\n",
      " Factor w/ 10 levels \"brown\",\"buff\",..: 1 10 9 9 4 10 9 9 9 10 ...\n",
      " Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 1 2 2 2 2 2 ...\n",
      " Factor w/ 9 levels \"almond\",\"anise\",..: 8 1 2 8 7 1 1 2 8 1 ...\n",
      " Factor w/ 2 levels \"attached\",\"free\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " Factor w/ 2 levels \"close\",\"crowded\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " Factor w/ 2 levels \"broad\",\"narrow\": 2 1 1 2 1 1 1 1 2 1 ...\n",
      " Factor w/ 12 levels \"black\",\"brown\",..: 1 1 2 2 1 2 5 2 8 5 ...\n",
      " Factor w/ 2 levels \"enlarging\",\"tapering\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " Factor w/ 5 levels \"bulbous\",\"club\",..: 3 2 2 3 3 2 2 2 3 2 ...\n",
      " Factor w/ 4 levels \"fibrous\",\"scaly\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " Factor w/ 4 levels \"fibrous\",\"scaly\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " Factor w/ 9 levels \"brown\",\"buff\",..: 8 8 8 8 8 8 8 8 8 8 ...\n",
      " Factor w/ 9 levels \"brown\",\"buff\",..: 8 8 8 8 8 8 8 8 8 8 ...\n",
      " Factor w/ 1 level \"partial\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " Factor w/ 4 levels \"brown\",\"orange\",..: 3 3 3 3 3 3 3 3 3 3 ...\n",
      " Factor w/ 3 levels \"none\",\"one\",\"two\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " Factor w/ 5 levels \"evanescent\",\"flaring\",..: 5 5 5 5 1 5 5 5 5 5 ...\n",
      " Factor w/ 9 levels \"black\",\"brown\",..: 1 2 2 1 2 1 1 2 1 1 ...\n",
      " Factor w/ 6 levels \"abundant\",\"clustered\",..: 4 3 3 4 1 3 3 4 5 4 ...\n",
      " Factor w/ 7 levels \"grasses\",\"leaves\",..: 5 1 3 5 1 1 3 3 1 3 ...\n"
     ]
    }
   ],
   "source": [
    "#Assignment 2\n",
    "for ( i in 1:length(mushrooms) ) {\n",
    "    str(mushrooms[[i]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the `str()` function on all the variables it shows that using `str()` on the dataframe it describes the dataframe itself displaying the object type, the total amount of objects, the variables. \n",
    "\n",
    "When using `str()` on all the variables separately it doesn't show the variable names anymore and only the content type and head of content. \n",
    "\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "###  Record the output and your analysis of the output in your learning journal. How does the classifier perform? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odor:\n",
       "\talmond\t-> edible\n",
       "\tanise\t-> edible\n",
       "\tcreosote\t-> poisonous\n",
       "\tfishy\t-> poisonous\n",
       "\tfoul\t-> poisonous\n",
       "\tmusty\t-> poisonous\n",
       "\tnone\t-> edible\n",
       "\tpungent\t-> poisonous\n",
       "\tspicy\t-> poisonous\n",
       "(8004/8124 instances correct)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Assignment 3\n",
    "mushroom_1r <- OneR(type~., data=mushrooms)\n",
    "mushroom_1r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier got 8004 out of 8124 instances correct. I think it performed quite well.\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "### Analyze the Summary and Confusion Matrix printouts. Are there any terms that you do not understand? Look these up in google, and record their meaning. \n",
    "\n",
    "### Also, give an interpretation of the confusion matrix. How did the classifier perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "=== Summary ===\n",
       "\n",
       "Correctly Classified Instances        8004               98.5229 %\n",
       "Incorrectly Classified Instances       120                1.4771 %\n",
       "Kappa statistic                          0.9704\n",
       "Mean absolute error                      0.0148\n",
       "Root mean squared error                  0.1215\n",
       "Relative absolute error                  2.958  %\n",
       "Root relative squared error             24.323  %\n",
       "Total Number of Instances             8124     \n",
       "\n",
       "=== Confusion Matrix ===\n",
       "\n",
       "    a    b   <-- classified as\n",
       " 4208    0 |    a = edible\n",
       "  120 3796 |    b = poisonous"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Assignment 4\n",
    "summary(mushroom_1r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "120 instances were classfied incorrectly as edible which is bad for the mushroom gatherer, he poisoned now :'(\n",
    "\n",
    "All poisonous instances have been correctly classified as poisonous.\n",
    "\n",
    "\n",
    "Unknown terms:\n",
    "\n",
    "- Kappa statistics: value to mesaure interrater agreement which describes the degree of agreement between to parties.\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNMENT 5: Analyze the Summary and Confusion Matrix printouts again. Did this classifier perform better? If yes, how so?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JRIP rules:\n",
       "===========\n",
       "\n",
       "(odor = foul) => type=poisonous (2160.0/0.0)\n",
       "(gill_size = narrow) and (gill_color = buff) => type=poisonous (1152.0/0.0)\n",
       "(gill_size = narrow) and (odor = pungent) => type=poisonous (256.0/0.0)\n",
       "(odor = creosote) => type=poisonous (192.0/0.0)\n",
       "(spore_print_color = green) => type=poisonous (72.0/0.0)\n",
       "(stalk_surface_below_ring = scaly) and (stalk_surface_above_ring = silky) => type=poisonous (68.0/0.0)\n",
       "(habitat = leaves) and (gill_attachment = free) and (population = clustered) => type=poisonous (16.0/0.0)\n",
       " => type=edible (4208.0/0.0)\n",
       "\n",
       "Number of Rules : 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "=== Summary ===\n",
       "\n",
       "Correctly Classified Instances        8124              100      %\n",
       "Incorrectly Classified Instances         0                0      %\n",
       "Kappa statistic                          1     \n",
       "Mean absolute error                      0     \n",
       "Root mean squared error                  0     \n",
       "Relative absolute error                  0      %\n",
       "Root relative squared error              0      %\n",
       "Total Number of Instances             8124     \n",
       "\n",
       "=== Confusion Matrix ===\n",
       "\n",
       "    a    b   <-- classified as\n",
       " 4208    0 |    a = edible\n",
       "    0 3916 |    b = poisonous"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mushroom_JRip <- JRip(type ~ ., data = mushrooms)\n",
    "mushroom_JRip\n",
    "summary(mushroom_JRip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using JRip all instances have been classified correctly.\n",
    "\n",
    "In the previously used OneR classifier poisonousness was determined by the different odors only.\n",
    "\n",
    "JRip determined more rules that not only described one condition, but also combinations of features in boolean expressions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Exercise\n",
    "\n",
    "## Neural networks in Healthcare\n",
    "\n",
    "\n",
    "### Predicting cancer outcomes from histology and genomics using convolutional networks\n",
    "#### http://www.pnas.org/content/115/13/E2970\n",
    "\n",
    "### two publications from pubmed\n",
    "\n",
    "What, medical background\n",
    "what method, what neural network\n",
    "compare both publications\n",
    "\n",
    "pubmed search string: artificial neural networks.\n",
    "\n",
    "found articles: \n",
    "#### Predicting cancer outcomes from histology and genomics using convolutional networks.\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/29531073\n",
    "\n",
    "#### Deep Learning for Drug Design: an Artificial Intelligence Paradigm for Drug Discovery in the Big Data Era.\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/29603063\n",
    "\n",
    "\n",
    "\n",
    "# TODO\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Exercise\n",
    "\n",
    "## Neural networks in R\n",
    "\n",
    "\n",
    "loaded the concrete.csv into variable using read.csv from library RWeka.\n",
    "\n",
    "look at it using str()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"describe structure of concrete and its variables using str()\"\n",
      "'data.frame':\t1030 obs. of  9 variables:\n",
      " $ cement      : num  141 169 250 266 155 ...\n",
      " $ slag        : num  212 42.2 0 114 183.4 ...\n",
      " $ ash         : num  0 124.3 95.7 0 0 ...\n",
      " $ water       : num  204 158 187 228 193 ...\n",
      " $ superplastic: num  0 10.8 5.5 0 9.1 0 0 6.4 0 9 ...\n",
      " $ coarseagg   : num  972 1081 957 932 1047 ...\n",
      " $ fineagg     : num  748 796 861 670 697 ...\n",
      " $ age         : int  28 14 28 28 28 90 7 56 28 28 ...\n",
      " $ strength    : num  29.9 23.5 29.2 45.9 18.3 ...\n",
      " num [1:1030] 141 169 250 266 155 ...\n",
      " num [1:1030] 212 42.2 0 114 183.4 ...\n",
      " num [1:1030] 0 124.3 95.7 0 0 ...\n",
      " num [1:1030] 204 158 187 228 193 ...\n",
      " num [1:1030] 0 10.8 5.5 0 9.1 0 0 6.4 0 9 ...\n",
      " num [1:1030] 972 1081 957 932 1047 ...\n",
      " num [1:1030] 748 796 861 670 697 ...\n",
      " int [1:1030] 28 14 28 28 28 90 7 56 28 28 ...\n",
      " num [1:1030] 29.9 23.5 29.2 45.9 18.3 ...\n"
     ]
    }
   ],
   "source": [
    "library(neuralnet)\n",
    "\n",
    "concrete <- read.csv(\"concrete.csv\")\n",
    "\n",
    "print(\"describe structure of concrete and its variables using str()\")\n",
    "str(concrete)\n",
    "for ( i in 1:length(concrete) ) {\n",
    "    str(concrete[[i]])\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSIGNMENT 1: Take a look at the database, and describe it in your learning journal. \n",
    "\n",
    "9 Variables, 1030 Objects, only numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Cement:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  102 108.3   116 122.6   132   133 \n",
       "    4     4     4     4     2     5 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Slag:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0   11 13.6   15 17.2 17.5 \n",
       " 471    4    5    5    1    1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Ash:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0 24.5   59   60   71 71.5 \n",
       " 566   15    1    1    1    1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Water:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "121.8 126.6   127 127.3 137.8   140 \n",
       "    5     5     1     1     5     1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Superplastic:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0 1.7 1.9   2 2.2 2.5 \n",
       "379   4   1   1   1   2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Coarseagg:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  801 801.1 801.4   811   814 814.1 \n",
       "    4     1     1     2     1     1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"fineagg:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  594   605 611.8   612   613 613.2 \n",
       "   30     5     5     1    22     2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"age:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  1   3   7  14  28  56 \n",
       "  2 134 126  62 425  91 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"strength:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "2.33 3.32 4.57 4.78 4.83  4.9 \n",
       "   1    1    1    1    1    1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Cement:\")\n",
    "head(table(concrete$cement))\n",
    "print(\"Slag:\")\n",
    "head(table(concrete$slag))\n",
    "print(\"Ash:\")\n",
    "head(table(concrete$ash))\n",
    "print(\"Water:\")\n",
    "head(table(concrete$water))\n",
    "print(\"Superplastic:\")\n",
    "head(table(concrete$superplastic))\n",
    "print(\"Coarseagg:\")\n",
    "head(table(concrete$coarseagg))\n",
    "print(\"fineagg:\")\n",
    "head(table(concrete$fineagg))\n",
    "print(\"age:\")\n",
    "head(table(concrete$age))\n",
    "print(\"strength:\")\n",
    "head(table(concrete$strength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "\n",
    "Problem here is that the values are not between one and 0, therefore not being normalized.\n",
    "In neural networks values are activated using activation functions like the very basic sigmoid function or the ReLU (Rectified Linear Unit) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       " 0.0000  0.2664  0.4001  0.4172  0.5457  1.0000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "   2.33   23.71   34.45   35.82   46.13   82.60 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"summary of concrete_train:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     cement            slag              ash             water       \n",
       " Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.:0.2055   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.3450  \n",
       " Median :0.3628   Median :0.05565   Median :0.0000   Median :0.5104  \n",
       " Mean   :0.4055   Mean   :0.20589   Mean   :0.2627   Mean   :0.4824  \n",
       " 3rd Qu.:0.5662   3rd Qu.:0.39733   3rd Qu.:0.5912   3rd Qu.:0.5679  \n",
       " Max.   :1.0000   Max.   :0.95186   Max.   :0.9995   Max.   :1.0000  \n",
       "  superplastic      coarseagg         fineagg            age         \n",
       " Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n",
       " 1st Qu.:0.0000   1st Qu.:0.3808   1st Qu.:0.3352   1st Qu.:0.03571  \n",
       " Median :0.1863   Median :0.4855   Median :0.4629   Median :0.07418  \n",
       " Mean   :0.1851   Mean   :0.5067   Mean   :0.4504   Mean   :0.12523  \n",
       " 3rd Qu.:0.3137   3rd Qu.:0.6657   3rd Qu.:0.5795   3rd Qu.:0.15110  \n",
       " Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n",
       "    strength     \n",
       " Min.   :0.0000  \n",
       " 1st Qu.:0.2655  \n",
       " Median :0.3921  \n",
       " Mean   :0.4152  \n",
       " 3rd Qu.:0.5469  \n",
       " Max.   :0.9894  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"summary of concrete_test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     cement             slag              ash             water       \n",
       " Min.   :0.01438   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.:0.22374   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.3291  \n",
       " Median :0.42466   Median :0.06678   Median :0.0000   Median :0.4617  \n",
       " Mean   :0.41973   Mean   :0.20475   Mean   :0.2952   Mean   :0.4623  \n",
       " 3rd Qu.:0.58676   3rd Qu.:0.40122   3rd Qu.:0.5927   3rd Qu.:0.5607  \n",
       " Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :0.9177  \n",
       "  superplastic      coarseagg         fineagg            age         \n",
       " Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n",
       " 1st Qu.:0.0000   1st Qu.:0.3674   1st Qu.:0.3588   1st Qu.:0.01648  \n",
       " Median :0.2422   Median :0.4826   Median :0.4681   Median :0.07418  \n",
       " Mean   :0.2156   Mean   :0.4790   Mean   :0.4510   Mean   :0.11509  \n",
       " 3rd Qu.:0.3261   3rd Qu.:0.6448   3rd Qu.:0.5725   3rd Qu.:0.07418  \n",
       " Max.   :1.0000   Max.   :0.9689   Max.   :1.0000   Max.   :1.00000  \n",
       "    strength      \n",
       " Min.   :0.03052  \n",
       " 1st Qu.:0.27084  \n",
       " Median :0.41074  \n",
       " Mean   :0.42329  \n",
       " 3rd Qu.:0.53258  \n",
       " Max.   :1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize <- function(x) {\n",
    " return((x - min(x)) / (max(x) - min(x)))\n",
    "}\n",
    "\n",
    "concrete_norm <- as.data.frame(lapply(concrete, normalize))\n",
    "\n",
    "summary(concrete_norm$strength)\n",
    "summary(concrete$strength)\n",
    "\n",
    "concrete_train <- concrete_norm[1:773, ]\n",
    "concrete_test <- concrete_norm[774:1030, ]\n",
    "\n",
    "print(\"summary of concrete_train:\")\n",
    "summary(concrete_train)\n",
    "\n",
    "print(\"summary of concrete_test\")\n",
    "summary(concrete_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 Compare summary of training and test data sets\n",
    "In both data sets the minimal and maximal values are exactly or at least close to 0 and 1. whiche lets assume the data is quite evenly distributed.\n",
    "\n",
    "Also the other statistical key figures like 1st quartile, median, mean and 3rd quartile are similar.\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete_model <- neuralnet(strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age, data = concrete_train)\n",
    "\n",
    "plot(concrete_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4 describe the plot\n",
    "\n",
    "\n",
    "As jupyterlab did not render the plot I had to run the code separately in an R console and embed the rendered plots in this markdown cell.\n",
    "\n",
    "![concrete_model](img/concrete_model.png)\n",
    "\n",
    "\n",
    "The plot shows our parameters as input neurons going with specific weights into a single hidden layer with a single hidden neuron. Error is over 5000 and 1283 steps were taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.806376645</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.806376645\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.806376645 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       \n",
       "[1,] 0.806376645"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.9294700512</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.9294700512\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.9294700512 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]        \n",
       "[1,] 0.9294700512"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.9448685089</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.9448685089\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.9448685089 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]        \n",
       "[1,] 0.9448685089"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.9364411122</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.9364411122\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.9364411122 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]        \n",
       "[1,] 0.9364411122"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_results <- compute(concrete_model, concrete_test[1:8])\n",
    "predicted_strength <- model_results$net.result\n",
    "cor(predicted_strength, concrete_test$strength)\n",
    "\n",
    "concrete_model2 <- neuralnet(strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age, data = concrete_train, hidden = 5)\n",
    "plot(concrete_model2)\n",
    "model_results2 <- compute(concrete_model2, concrete_test[1:8])\n",
    "predicted_strength2 <- model_results2$net.result\n",
    "cor(predicted_strength2, concrete_test$strength)\n",
    "\n",
    "concrete_model3 <- neuralnet(strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age, data = concrete_train, hidden = 10)\n",
    "plot(concrete_model3)\n",
    "model_results3 <- compute(concrete_model3, concrete_test[1:8])\n",
    "predicted_strength3 <- model_results3$net.result\n",
    "cor(predicted_strength3, concrete_test$strength)\n",
    "\n",
    "concrete_model4 <- neuralnet(strength ~ cement + slag + ash + water + superplastic + coarseagg + fineagg + age, data = concrete_train, hidden = 20)\n",
    "plot(concrete_model4)\n",
    "model_results4 <- compute(concrete_model4, concrete_test[1:8])\n",
    "predicted_strength4 <- model_results4$net.result\n",
    "cor(predicted_strength4, concrete_test$strength)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5,6,7,8\n",
    "\n",
    "#### concrete_model2\n",
    "\n",
    "![concrete_model2](img/concrete_model2.png)\n",
    "\n",
    "#### concrete_model3\n",
    "\n",
    "![concrete_model3](img/concrete_model3.png)\n",
    "\n",
    "#### concrete_model4\n",
    "\n",
    "![concrete_model4](img/concrete_model4.png)\n",
    "\n",
    "\n",
    "\n",
    "Hidden nodes increase and also the amount of connections between the nodes.\n",
    "Corellation increases until 10 hidden nodes. The next model created with 20 hidden nodes took significantly longer to compute and yielded a worse corellation than the model with only 10 hidden nodes which also took not so long to compute.\n",
    "\n",
    "Error went from 5 down to close to 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Exercise\n",
    "\n",
    "## Neural networks in R\n",
    "### OCR 03.05.2018\n",
    "\n",
    "### ASSIGNMENT 1: Take a look at the database, and describe it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t20000 obs. of  17 variables:\n",
      " $ letter: Factor w/ 26 levels \"A\",\"B\",\"C\",\"D\",..: 20 9 4 14 7 19 2 1 10 13 ...\n",
      " $ xbox  : int  2 5 4 7 2 4 4 1 2 11 ...\n",
      " $ ybox  : int  8 12 11 11 1 11 2 1 2 15 ...\n",
      " $ width : int  3 3 6 6 3 5 5 3 4 13 ...\n",
      " $ height: int  5 7 8 6 1 8 4 2 4 9 ...\n",
      " $ onpix : int  1 2 6 3 1 3 4 1 2 7 ...\n",
      " $ xbar  : int  8 10 10 5 8 8 8 8 10 13 ...\n",
      " $ ybar  : int  13 5 6 9 6 8 7 2 6 2 ...\n",
      " $ x2bar : int  0 5 2 4 6 6 6 2 2 6 ...\n",
      " $ y2bar : int  6 4 6 6 6 9 6 2 6 2 ...\n",
      " $ xybar : int  6 13 10 4 6 5 7 8 12 12 ...\n",
      " $ x2ybar: int  10 3 3 4 5 6 6 2 4 1 ...\n",
      " $ xy2bar: int  8 9 7 10 9 6 6 8 8 9 ...\n",
      " $ xedge : int  0 2 3 6 1 0 2 1 1 8 ...\n",
      " $ xedgey: int  8 8 7 10 7 8 8 6 6 1 ...\n",
      " $ yedge : int  0 4 3 2 5 9 7 2 1 1 ...\n",
      " $ yedgex: int  8 10 9 8 10 7 10 7 7 8 ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>letter</th><th scope=col>xbox</th><th scope=col>ybox</th><th scope=col>width</th><th scope=col>height</th><th scope=col>onpix</th><th scope=col>xbar</th><th scope=col>ybar</th><th scope=col>x2bar</th><th scope=col>y2bar</th><th scope=col>xybar</th><th scope=col>x2ybar</th><th scope=col>xy2bar</th><th scope=col>xedge</th><th scope=col>xedgey</th><th scope=col>yedge</th><th scope=col>yedgex</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>T </td><td>2 </td><td> 8</td><td>3 </td><td>5 </td><td>1 </td><td> 8</td><td>13</td><td>0 </td><td>6 </td><td> 6</td><td>10</td><td> 8</td><td>0 </td><td> 8</td><td>0 </td><td> 8</td></tr>\n",
       "\t<tr><td>I </td><td>5 </td><td>12</td><td>3 </td><td>7 </td><td>2 </td><td>10</td><td> 5</td><td>5 </td><td>4 </td><td>13</td><td> 3</td><td> 9</td><td>2 </td><td> 8</td><td>4 </td><td>10</td></tr>\n",
       "\t<tr><td>D </td><td>4 </td><td>11</td><td>6 </td><td>8 </td><td>6 </td><td>10</td><td> 6</td><td>2 </td><td>6 </td><td>10</td><td> 3</td><td> 7</td><td>3 </td><td> 7</td><td>3 </td><td> 9</td></tr>\n",
       "\t<tr><td>N </td><td>7 </td><td>11</td><td>6 </td><td>6 </td><td>3 </td><td> 5</td><td> 9</td><td>4 </td><td>6 </td><td> 4</td><td> 4</td><td>10</td><td>6 </td><td>10</td><td>2 </td><td> 8</td></tr>\n",
       "\t<tr><td>G </td><td>2 </td><td> 1</td><td>3 </td><td>1 </td><td>1 </td><td> 8</td><td> 6</td><td>6 </td><td>6 </td><td> 6</td><td> 5</td><td> 9</td><td>1 </td><td> 7</td><td>5 </td><td>10</td></tr>\n",
       "\t<tr><td>S </td><td>4 </td><td>11</td><td>5 </td><td>8 </td><td>3 </td><td> 8</td><td> 8</td><td>6 </td><td>9 </td><td> 5</td><td> 6</td><td> 6</td><td>0 </td><td> 8</td><td>9 </td><td> 7</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllll}\n",
       " letter & xbox & ybox & width & height & onpix & xbar & ybar & x2bar & y2bar & xybar & x2ybar & xy2bar & xedge & xedgey & yedge & yedgex\\\\\n",
       "\\hline\n",
       "\t T  & 2  &  8 & 3  & 5  & 1  &  8 & 13 & 0  & 6  &  6 & 10 &  8 & 0  &  8 & 0  &  8\\\\\n",
       "\t I  & 5  & 12 & 3  & 7  & 2  & 10 &  5 & 5  & 4  & 13 &  3 &  9 & 2  &  8 & 4  & 10\\\\\n",
       "\t D  & 4  & 11 & 6  & 8  & 6  & 10 &  6 & 2  & 6  & 10 &  3 &  7 & 3  &  7 & 3  &  9\\\\\n",
       "\t N  & 7  & 11 & 6  & 6  & 3  &  5 &  9 & 4  & 6  &  4 &  4 & 10 & 6  & 10 & 2  &  8\\\\\n",
       "\t G  & 2  &  1 & 3  & 1  & 1  &  8 &  6 & 6  & 6  &  6 &  5 &  9 & 1  &  7 & 5  & 10\\\\\n",
       "\t S  & 4  & 11 & 5  & 8  & 3  &  8 &  8 & 6  & 9  &  5 &  6 &  6 & 0  &  8 & 9  &  7\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "letter | xbox | ybox | width | height | onpix | xbar | ybar | x2bar | y2bar | xybar | x2ybar | xy2bar | xedge | xedgey | yedge | yedgex | \n",
       "|---|---|---|---|---|---|\n",
       "| T  | 2  |  8 | 3  | 5  | 1  |  8 | 13 | 0  | 6  |  6 | 10 |  8 | 0  |  8 | 0  |  8 | \n",
       "| I  | 5  | 12 | 3  | 7  | 2  | 10 |  5 | 5  | 4  | 13 |  3 |  9 | 2  |  8 | 4  | 10 | \n",
       "| D  | 4  | 11 | 6  | 8  | 6  | 10 |  6 | 2  | 6  | 10 |  3 |  7 | 3  |  7 | 3  |  9 | \n",
       "| N  | 7  | 11 | 6  | 6  | 3  |  5 |  9 | 4  | 6  |  4 |  4 | 10 | 6  | 10 | 2  |  8 | \n",
       "| G  | 2  |  1 | 3  | 1  | 1  |  8 |  6 | 6  | 6  |  6 |  5 |  9 | 1  |  7 | 5  | 10 | \n",
       "| S  | 4  | 11 | 5  | 8  | 3  |  8 |  8 | 6  | 9  |  5 |  6 |  6 | 0  |  8 | 9  |  7 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  letter xbox ybox width height onpix xbar ybar x2bar y2bar xybar x2ybar xy2bar\n",
       "1 T      2     8   3     5      1      8   13   0     6      6    10      8    \n",
       "2 I      5    12   3     7      2     10    5   5     4     13     3      9    \n",
       "3 D      4    11   6     8      6     10    6   2     6     10     3      7    \n",
       "4 N      7    11   6     6      3      5    9   4     6      4     4     10    \n",
       "5 G      2     1   3     1      1      8    6   6     6      6     5      9    \n",
       "6 S      4    11   5     8      3      8    8   6     9      5     6      6    \n",
       "  xedge xedgey yedge yedgex\n",
       "1 0      8     0      8    \n",
       "2 2      8     4     10    \n",
       "3 3      7     3      9    \n",
       "4 6     10     2      8    \n",
       "5 1      7     5     10    \n",
       "6 0      8     9      7    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letters <- read.csv(\"letterdata.csv\")\n",
    "str(letters)\n",
    "head(letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the data we can see several columns specifying locations and boundaries on a pixel level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Support Vector Machine object of class \"ksvm\" \n",
       "\n",
       "SV type: C-svc  (classification) \n",
       " parameter : cost C = 1 \n",
       "\n",
       "Linear (vanilla) kernel function. \n",
       "\n",
       "Number of Support Vectors : 7037 \n",
       "\n",
       "Objective Function Value : -14.1746 -20.0072 -23.5628 -6.2009 -7.5524 -32.7694 -49.9786 -18.1824 -62.1111 -32.7284 -16.2209 -32.2837 -28.9777 -51.2195 -13.276 -35.6217 -30.8612 -16.5256 -14.6811 -32.7475 -30.3219 -7.7956 -11.8138 -32.3463 -13.1262 -9.2692 -153.1654 -52.9678 -76.7744 -119.2067 -165.4437 -54.6237 -41.9809 -67.2688 -25.1959 -27.6371 -26.4102 -35.5583 -41.2597 -122.164 -187.9178 -222.0856 -21.4765 -10.3752 -56.3684 -12.2277 -49.4899 -9.3372 -19.2092 -11.1776 -100.2186 -29.1397 -238.0516 -77.1985 -8.3339 -4.5308 -139.8534 -80.8854 -20.3642 -13.0245 -82.5151 -14.5032 -26.7509 -18.5713 -23.9511 -27.3034 -53.2731 -11.4773 -5.12 -13.9504 -4.4982 -3.5755 -8.4914 -40.9716 -49.8182 -190.0269 -43.8594 -44.8667 -45.2596 -13.5561 -17.7664 -87.4105 -107.1056 -37.0245 -30.7133 -112.3218 -32.9619 -27.2971 -35.5836 -17.8586 -5.1391 -43.4094 -7.7843 -16.6785 -58.5103 -159.9936 -49.0782 -37.8426 -32.8002 -74.5249 -133.3423 -11.1638 -5.3575 -12.438 -30.9907 -141.6924 -54.2953 -179.0114 -99.8896 -10.288 -15.1553 -3.7815 -67.6123 -7.696 -88.9304 -47.6448 -94.3718 -70.2733 -71.5057 -21.7854 -12.7657 -7.4383 -23.502 -13.1055 -239.9708 -30.4193 -25.2113 -136.2795 -140.9565 -9.8122 -34.4584 -6.3039 -60.8421 -66.5793 -27.2816 -214.3225 -34.7796 -16.7631 -135.7821 -160.6279 -45.2949 -25.1023 -144.9059 -82.2352 -327.7154 -142.0613 -158.8821 -32.2181 -32.8887 -52.9641 -25.4937 -47.9936 -6.8991 -9.7293 -36.436 -70.3907 -187.7611 -46.9371 -89.8103 -143.4213 -624.3645 -119.2204 -145.4435 -327.7748 -33.3255 -64.0607 -145.4831 -116.5903 -36.2977 -66.3762 -44.8248 -7.5088 -217.9246 -12.9699 -30.504 -2.0369 -6.126 -14.4448 -21.6337 -57.3084 -20.6915 -184.3625 -20.1052 -4.1484 -4.5344 -0.828 -121.4411 -7.9486 -58.5604 -21.4878 -13.5476 -5.646 -15.629 -28.9576 -20.5959 -76.7111 -27.0119 -94.7101 -15.1713 -10.0222 -7.6394 -1.5784 -87.6952 -6.2239 -99.3711 -101.0906 -45.6639 -24.0725 -61.7702 -24.1583 -52.2368 -234.3264 -39.9749 -48.8556 -34.1464 -20.9664 -11.4525 -123.0277 -6.4903 -5.1865 -8.8016 -9.4618 -21.7742 -24.2361 -123.3984 -31.4404 -88.3901 -30.0924 -13.8198 -9.2701 -3.0823 -87.9624 -6.3845 -13.968 -65.0702 -105.523 -13.7403 -13.7625 -50.4223 -2.933 -8.4289 -80.3381 -36.4147 -112.7485 -4.1711 -7.8989 -1.2676 -90.8037 -21.4919 -7.2235 -47.9557 -3.383 -20.433 -64.6138 -45.5781 -56.1309 -6.1345 -18.6307 -2.374 -72.2553 -111.1885 -106.7664 -23.1323 -19.3765 -54.9819 -34.2953 -64.4756 -20.4115 -6.689 -4.378 -59.141 -34.2468 -58.1509 -33.8665 -10.6902 -53.1387 -13.7478 -20.1987 -55.0923 -3.8058 -60.0382 -235.4841 -12.6837 -11.7407 -17.3058 -9.7167 -65.8498 -17.1051 -42.8131 -53.1054 -25.0437 -15.302 -44.0749 -16.9582 -62.9773 -5.204 -5.2963 -86.1704 -3.7209 -6.3445 -1.1264 -122.5771 -23.9041 -355.0145 -31.1013 -32.619 -4.9664 -84.1048 -134.5957 -72.8371 -23.9002 -35.3077 -11.7119 -22.2889 -1.8598 -59.2174 -8.8994 -150.742 -1.8533 -1.9711 -9.9676 -0.5207 -26.9229 -30.429 -5.6289 \n",
       "Training error : 0.130062 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letters_train <- letters[1:16000, ]\n",
    "letters_test <- letters[16001:20000, ]\n",
    " letters <- read.csv(\"letterdata.csv\")\n",
    "#install.packages(\"kernlab\") #only needs to be installed once\n",
    "library(kernlab)\n",
    "\n",
    "letter_classifier <- ksvm(letter ~ ., data = letters_train, kernel = \"vanilladot\")\n",
    "\n",
    "letter_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2\n",
    "#### Analyze the output of the command > letter_classifier.\n",
    "\n",
    "Default kernel parameters are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>U</li>\n",
       "\t<li>N</li>\n",
       "\t<li>V</li>\n",
       "\t<li>X</li>\n",
       "\t<li>N</li>\n",
       "\t<li>H</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'A'</li>\n",
       "\t\t<li>'B'</li>\n",
       "\t\t<li>'C'</li>\n",
       "\t\t<li>'D'</li>\n",
       "\t\t<li>'E'</li>\n",
       "\t\t<li>'F'</li>\n",
       "\t\t<li>'G'</li>\n",
       "\t\t<li>'H'</li>\n",
       "\t\t<li>'I'</li>\n",
       "\t\t<li>'J'</li>\n",
       "\t\t<li>'K'</li>\n",
       "\t\t<li>'L'</li>\n",
       "\t\t<li>'M'</li>\n",
       "\t\t<li>'N'</li>\n",
       "\t\t<li>'O'</li>\n",
       "\t\t<li>'P'</li>\n",
       "\t\t<li>'Q'</li>\n",
       "\t\t<li>'R'</li>\n",
       "\t\t<li>'S'</li>\n",
       "\t\t<li>'T'</li>\n",
       "\t\t<li>'U'</li>\n",
       "\t\t<li>'V'</li>\n",
       "\t\t<li>'W'</li>\n",
       "\t\t<li>'X'</li>\n",
       "\t\t<li>'Y'</li>\n",
       "\t\t<li>'Z'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item U\n",
       "\\item N\n",
       "\\item V\n",
       "\\item X\n",
       "\\item N\n",
       "\\item H\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'A'\n",
       "\\item 'B'\n",
       "\\item 'C'\n",
       "\\item 'D'\n",
       "\\item 'E'\n",
       "\\item 'F'\n",
       "\\item 'G'\n",
       "\\item 'H'\n",
       "\\item 'I'\n",
       "\\item 'J'\n",
       "\\item 'K'\n",
       "\\item 'L'\n",
       "\\item 'M'\n",
       "\\item 'N'\n",
       "\\item 'O'\n",
       "\\item 'P'\n",
       "\\item 'Q'\n",
       "\\item 'R'\n",
       "\\item 'S'\n",
       "\\item 'T'\n",
       "\\item 'U'\n",
       "\\item 'V'\n",
       "\\item 'W'\n",
       "\\item 'X'\n",
       "\\item 'Y'\n",
       "\\item 'Z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. U\n",
       "2. N\n",
       "3. V\n",
       "4. X\n",
       "5. N\n",
       "6. H\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'A'\n",
       "2. 'B'\n",
       "3. 'C'\n",
       "4. 'D'\n",
       "5. 'E'\n",
       "6. 'F'\n",
       "7. 'G'\n",
       "8. 'H'\n",
       "9. 'I'\n",
       "10. 'J'\n",
       "11. 'K'\n",
       "12. 'L'\n",
       "13. 'M'\n",
       "14. 'N'\n",
       "15. 'O'\n",
       "16. 'P'\n",
       "17. 'Q'\n",
       "18. 'R'\n",
       "19. 'S'\n",
       "20. 'T'\n",
       "21. 'U'\n",
       "22. 'V'\n",
       "23. 'W'\n",
       "24. 'X'\n",
       "25. 'Y'\n",
       "26. 'Z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] U N V X N H\n",
       "Levels: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                  \n",
       "letter_predictions   A   B   C   D   E   F   G   H   I   J   K   L   M   N   O\n",
       "                 A 144   0   0   0   0   0   0   0   0   1   0   0   1   2   2\n",
       "                 B   0 121   0   5   2   0   1   2   0   0   1   0   1   0   0\n",
       "                 C   0   0 120   0   4   0  10   2   2   0   1   3   0   0   2\n",
       "                 D   2   2   0 156   0   1   3  10   4   3   4   3   0   5   5\n",
       "                 E   0   0   5   0 127   3   1   1   0   0   3   4   0   0   0\n",
       "                 F   0   0   0   0   0 138   2   2   6   0   0   0   0   0   0\n",
       "                 G   1   1   2   1   9   2 123   2   0   0   1   2   1   0   1\n",
       "                 H   0   0   0   1   0   1   0 102   0   2   3   2   3   4  20\n",
       "                 I   0   1   0   0   0   1   0   0 141   8   0   0   0   0   0\n",
       "                 J   0   1   0   0   0   1   0   2   5 128   0   0   0   0   1\n",
       "                 K   1   1   9   0   0   0   2   5   0   0 118   0   0   2   0\n",
       "                 L   0   0   0   0   2   0   1   1   0   0   0 133   0   0   0\n",
       "                 M   0   0   1   1   0   0   1   1   0   0   0   0 135   4   0\n",
       "                 N   0   0   0   0   0   1   0   1   0   0   0   0   0 145   0\n",
       "                 O   1   0   2   1   0   0   1   2   0   1   0   0   0   1  99\n",
       "                 P   0   0   0   1   0   2   1   0   0   0   0   0   0   0   2\n",
       "                 Q   0   0   0   0   0   0   8   2   0   0   0   3   0   0   3\n",
       "                 R   0   7   0   0   1   0   3   8   0   0  13   0   0   1   1\n",
       "                 S   1   1   0   0   1   0   3   0   1   1   0   1   0   0   0\n",
       "                 T   0   0   0   0   3   2   0   0   0   0   1   0   0   0   0\n",
       "                 U   1   0   3   1   0   0   0   2   0   0   0   0   0   0   1\n",
       "                 V   0   0   0   0   0   1   3   4   0   0   0   0   1   2   1\n",
       "                 W   0   0   0   0   0   0   1   0   0   0   0   0   2   0   0\n",
       "                 X   0   1   0   0   2   0   0   1   3   0   1   6   0   0   1\n",
       "                 Y   3   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "                 Z   2   0   0   0   1   0   0   0   3   4   0   0   0   0   0\n",
       "                  \n",
       "letter_predictions   P   Q   R   S   T   U   V   W   X   Y   Z\n",
       "                 A   0   5   0   1   1   1   0   1   0   0   1\n",
       "                 B   2   2   3   5   0   0   2   0   1   0   0\n",
       "                 C   0   0   0   0   0   0   0   0   0   0   0\n",
       "                 D   3   1   4   0   0   0   0   0   3   3   1\n",
       "                 E   0   2   0  10   0   0   0   0   2   0   3\n",
       "                 F  16   0   0   3   0   0   1   0   1   2   0\n",
       "                 G   2   8   2   4   3   0   0   0   1   0   0\n",
       "                 H   0   2   3   0   3   0   2   0   0   1   0\n",
       "                 I   1   0   0   3   0   0   0   0   5   1   1\n",
       "                 J   1   3   0   2   0   0   0   0   1   0   6\n",
       "                 K   1   0   7   0   1   3   0   0   5   0   0\n",
       "                 L   0   1   0   5   0   0   0   0   0   0   1\n",
       "                 M   0   0   0   0   0   3   0   8   0   0   0\n",
       "                 N   0   0   3   0   0   1   0   2   0   0   0\n",
       "                 O   3   3   0   0   0   3   0   0   0   0   0\n",
       "                 P 130   0   0   0   0   0   0   0   0   1   0\n",
       "                 Q   1 124   0   5   0   0   0   0   0   2   0\n",
       "                 R   1   0 138   0   1   0   1   0   0   0   0\n",
       "                 S   0  14   0 101   3   0   0   0   2   0  10\n",
       "                 T   0   0   0   3 133   1   0   0   0   2   2\n",
       "                 U   0   0   0   0   0 152   0   0   1   1   0\n",
       "                 V   0   3   1   0   0   0 126   1   0   4   0\n",
       "                 W   0   0   0   0   0   4   4 127   0   0   0\n",
       "                 X   0   0   0   1   0   0   0   0 137   1   1\n",
       "                 Y   7   0   0   0   3   0   0   0   0 127   0\n",
       "                 Z   0   0   0  18   3   0   0   0   0   0 132"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "agreement\n",
       "FALSE  TRUE \n",
       "  643  3357 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letter_predictions <- predict(letter_classifier, letters_test)\n",
    "head(letter_predictions)\n",
    "\n",
    "table(letter_predictions, letters_test$letter)\n",
    "agreement <- letter_predictions == letters_test$letter\n",
    "table(agreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3\n",
    "In the table we can see that the detection is mostly right, but not nearly enough to be useful. 643 false predictions in comparison to 3357 right predictions which is almost an error rate of 20 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>U</li>\n",
       "\t<li>N</li>\n",
       "\t<li>V</li>\n",
       "\t<li>I</li>\n",
       "\t<li>N</li>\n",
       "\t<li>H</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'A'</li>\n",
       "\t\t<li>'B'</li>\n",
       "\t\t<li>'C'</li>\n",
       "\t\t<li>'D'</li>\n",
       "\t\t<li>'E'</li>\n",
       "\t\t<li>'F'</li>\n",
       "\t\t<li>'G'</li>\n",
       "\t\t<li>'H'</li>\n",
       "\t\t<li>'I'</li>\n",
       "\t\t<li>'J'</li>\n",
       "\t\t<li>'K'</li>\n",
       "\t\t<li>'L'</li>\n",
       "\t\t<li>'M'</li>\n",
       "\t\t<li>'N'</li>\n",
       "\t\t<li>'O'</li>\n",
       "\t\t<li>'P'</li>\n",
       "\t\t<li>'Q'</li>\n",
       "\t\t<li>'R'</li>\n",
       "\t\t<li>'S'</li>\n",
       "\t\t<li>'T'</li>\n",
       "\t\t<li>'U'</li>\n",
       "\t\t<li>'V'</li>\n",
       "\t\t<li>'W'</li>\n",
       "\t\t<li>'X'</li>\n",
       "\t\t<li>'Y'</li>\n",
       "\t\t<li>'Z'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item U\n",
       "\\item N\n",
       "\\item V\n",
       "\\item I\n",
       "\\item N\n",
       "\\item H\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'A'\n",
       "\\item 'B'\n",
       "\\item 'C'\n",
       "\\item 'D'\n",
       "\\item 'E'\n",
       "\\item 'F'\n",
       "\\item 'G'\n",
       "\\item 'H'\n",
       "\\item 'I'\n",
       "\\item 'J'\n",
       "\\item 'K'\n",
       "\\item 'L'\n",
       "\\item 'M'\n",
       "\\item 'N'\n",
       "\\item 'O'\n",
       "\\item 'P'\n",
       "\\item 'Q'\n",
       "\\item 'R'\n",
       "\\item 'S'\n",
       "\\item 'T'\n",
       "\\item 'U'\n",
       "\\item 'V'\n",
       "\\item 'W'\n",
       "\\item 'X'\n",
       "\\item 'Y'\n",
       "\\item 'Z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. U\n",
       "2. N\n",
       "3. V\n",
       "4. I\n",
       "5. N\n",
       "6. H\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'A'\n",
       "2. 'B'\n",
       "3. 'C'\n",
       "4. 'D'\n",
       "5. 'E'\n",
       "6. 'F'\n",
       "7. 'G'\n",
       "8. 'H'\n",
       "9. 'I'\n",
       "10. 'J'\n",
       "11. 'K'\n",
       "12. 'L'\n",
       "13. 'M'\n",
       "14. 'N'\n",
       "15. 'O'\n",
       "16. 'P'\n",
       "17. 'Q'\n",
       "18. 'R'\n",
       "19. 'S'\n",
       "20. 'T'\n",
       "21. 'U'\n",
       "22. 'V'\n",
       "23. 'W'\n",
       "24. 'X'\n",
       "25. 'Y'\n",
       "26. 'Z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] U N V I N H\n",
       "Levels: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                      \n",
       "letter_predictions_rbf   A   B   C   D   E   F   G   H   I   J   K   L   M   N\n",
       "                     A 151   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "                     B   0 128   0   3   0   1   0   2   0   0   0   1   2   1\n",
       "                     C   0   0 132   0   3   0   1   0   2   0   0   1   0   0\n",
       "                     D   1   1   0 161   0   0   2   9   2   3   1   0   0   1\n",
       "                     E   0   0   3   0 137   2   0   0   0   1   0   4   0   0\n",
       "                     F   0   0   0   0   0 148   0   0   3   0   0   0   0   0\n",
       "                     G   0   0   2   0   8   0 154   2   0   0   0   2   2   0\n",
       "                     H   0   1   0   1   0   0   2 124   0   1   2   1   1   3\n",
       "                     I   0   0   0   0   0   0   0   0 151   3   0   0   0   0\n",
       "                     J   0   0   0   0   0   0   0   0   3 136   0   0   0   0\n",
       "                     K   0   0   1   0   0   0   0   5   0   0 132   0   0   1\n",
       "                     L   0   0   0   0   0   0   1   0   0   0   0 141   0   0\n",
       "                     M   0   0   0   0   0   0   1   1   0   0   0   0 138   1\n",
       "                     N   0   0   0   0   0   2   0   0   0   0   0   0   0 150\n",
       "                     O   0   0   2   0   0   0   0   0   0   1   0   0   0   5\n",
       "                     P   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
       "                     Q   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
       "                     R   0   3   1   1   0   0   2   5   0   0   9   1   0   3\n",
       "                     S   0   2   0   0   0   0   0   0   1   2   0   2   0   0\n",
       "                     T   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "                     U   0   0   1   1   0   0   0   1   0   0   0   0   0   0\n",
       "                     V   0   0   0   0   0   0   0   0   0   0   0   0   1   1\n",
       "                     W   0   0   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "                     X   0   1   0   0   1   0   0   0   0   0   2   4   0   0\n",
       "                     Y   4   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
       "                     Z   0   0   0   0   3   0   0   0   2   1   0   0   0   0\n",
       "                      \n",
       "letter_predictions_rbf   O   P   Q   R   S   T   U   V   W   X   Y   Z\n",
       "                     A   0   0   3   0   0   1   0   0   0   0   0   0\n",
       "                     B   0   2   1   3   3   0   0   4   1   1   0   0\n",
       "                     C   0   0   0   0   0   0   0   0   0   0   0   0\n",
       "                     D   1   3   1   3   0   2   0   0   0   2   3   0\n",
       "                     E   0   1   0   0   2   1   0   0   0   0   0   2\n",
       "                     F   0  11   0   0   1   0   0   1   0   0   0   0\n",
       "                     G   2   1   0   0   0   2   0   0   0   0   0   0\n",
       "                     H   0   1   1   0   0   2   0   0   0   0   0   0\n",
       "                     I   0   0   0   0   0   0   0   0   0   1   0   0\n",
       "                     J   0   0   0   0   0   0   0   0   0   0   0   3\n",
       "                     K   0   0   0   3   0   0   0   0   0   2   0   0\n",
       "                     L   0   0   0   0   1   0   0   0   0   0   0   0\n",
       "                     M   0   0   0   0   0   0   1   0   2   0   0   0\n",
       "                     N   0   0   0   2   0   0   0   0   1   0   0   0\n",
       "                     O 129   2   4   0   0   0   1   0   0   0   0   0\n",
       "                     P   0 140   0   0   0   0   0   0   0   0   0   0\n",
       "                     Q   3   3 158   0   0   0   0   0   0   0   0   0\n",
       "                     R   2   1   0 150   0   1   0   0   0   0   0   0\n",
       "                     S   0   0   0   0 151   0   0   0   0   0   0   2\n",
       "                     T   0   0   0   0   1 140   0   0   0   0   1   0\n",
       "                     U   0   0   0   0   0   0 161   0   0   0   1   0\n",
       "                     V   0   0   0   0   0   0   2 131   0   0   1   0\n",
       "                     W   2   0   0   0   0   0   3   0 135   0   0   0\n",
       "                     X   0   0   0   0   1   1   0   0   0 153   1   1\n",
       "                     Y   0   3   0   0   0   1   0   0   0   0 138   0\n",
       "                     Z   0   0   0   0   1   0   0   0   0   0   0 150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "agreement_rbf\n",
       "FALSE  TRUE \n",
       "  281  3719 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letter_classifier_rbf <- ksvm(letter ~ ., data = letters_train, kernel = \"rbfdot\")\n",
    "letter_predictions_rbf <- predict(letter_classifier_rbf, letters_test)\n",
    "head(letter_predictions_rbf)\n",
    "\n",
    "table(letter_predictions_rbf, letters_test$letter)\n",
    "agreement_rbf <- letter_predictions_rbf == letters_test$letter\n",
    "table(agreement_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4\n",
    "\n",
    "After using a radial basis function network the error rate falls down to almost 7.5 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5: polydot and tanhdot performance\n",
    "\n",
    "First the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>U</li>\n",
       "\t<li>N</li>\n",
       "\t<li>V</li>\n",
       "\t<li>I</li>\n",
       "\t<li>N</li>\n",
       "\t<li>H</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'A'</li>\n",
       "\t\t<li>'B'</li>\n",
       "\t\t<li>'C'</li>\n",
       "\t\t<li>'D'</li>\n",
       "\t\t<li>'E'</li>\n",
       "\t\t<li>'F'</li>\n",
       "\t\t<li>'G'</li>\n",
       "\t\t<li>'H'</li>\n",
       "\t\t<li>'I'</li>\n",
       "\t\t<li>'J'</li>\n",
       "\t\t<li>'K'</li>\n",
       "\t\t<li>'L'</li>\n",
       "\t\t<li>'M'</li>\n",
       "\t\t<li>'N'</li>\n",
       "\t\t<li>'O'</li>\n",
       "\t\t<li>'P'</li>\n",
       "\t\t<li>'Q'</li>\n",
       "\t\t<li>'R'</li>\n",
       "\t\t<li>'S'</li>\n",
       "\t\t<li>'T'</li>\n",
       "\t\t<li>'U'</li>\n",
       "\t\t<li>'V'</li>\n",
       "\t\t<li>'W'</li>\n",
       "\t\t<li>'X'</li>\n",
       "\t\t<li>'Y'</li>\n",
       "\t\t<li>'Z'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item U\n",
       "\\item N\n",
       "\\item V\n",
       "\\item I\n",
       "\\item N\n",
       "\\item H\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'A'\n",
       "\\item 'B'\n",
       "\\item 'C'\n",
       "\\item 'D'\n",
       "\\item 'E'\n",
       "\\item 'F'\n",
       "\\item 'G'\n",
       "\\item 'H'\n",
       "\\item 'I'\n",
       "\\item 'J'\n",
       "\\item 'K'\n",
       "\\item 'L'\n",
       "\\item 'M'\n",
       "\\item 'N'\n",
       "\\item 'O'\n",
       "\\item 'P'\n",
       "\\item 'Q'\n",
       "\\item 'R'\n",
       "\\item 'S'\n",
       "\\item 'T'\n",
       "\\item 'U'\n",
       "\\item 'V'\n",
       "\\item 'W'\n",
       "\\item 'X'\n",
       "\\item 'Y'\n",
       "\\item 'Z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. U\n",
       "2. N\n",
       "3. V\n",
       "4. I\n",
       "5. N\n",
       "6. H\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'A'\n",
       "2. 'B'\n",
       "3. 'C'\n",
       "4. 'D'\n",
       "5. 'E'\n",
       "6. 'F'\n",
       "7. 'G'\n",
       "8. 'H'\n",
       "9. 'I'\n",
       "10. 'J'\n",
       "11. 'K'\n",
       "12. 'L'\n",
       "13. 'M'\n",
       "14. 'N'\n",
       "15. 'O'\n",
       "16. 'P'\n",
       "17. 'Q'\n",
       "18. 'R'\n",
       "19. 'S'\n",
       "20. 'T'\n",
       "21. 'U'\n",
       "22. 'V'\n",
       "23. 'W'\n",
       "24. 'X'\n",
       "25. 'Y'\n",
       "26. 'Z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] U N V I N H\n",
       "Levels: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                          \n",
       "letter_predictions_polydot   A   B   C   D   E   F   G   H   I   J   K   L   M\n",
       "                         A 145   0   0   0   0   0   0   0   0   2   0   0   0\n",
       "                         B   0 122   0   5   2   0   2   2   0   0   1   0   2\n",
       "                         C   0   0 121   0   4   1  11   1   2   0   1   3   0\n",
       "                         D   1   2   0 156   0   1   2  10   4   2   4   2   0\n",
       "                         E   0   0   5   0 128   3   1   0   0   1   3   5   0\n",
       "                         F   0   0   0   0   0 138   2   2   6   0   0   0   0\n",
       "                         G   0   1   2   1   9   1 124   4   0   0   0   2   1\n",
       "                         H   0   1   0   1   0   0   1 103   0   2   2   2   2\n",
       "                         I   0   1   0   0   0   1   0   0 141   8   0   0   0\n",
       "                         J   0   1   0   0   0   2   0   1   7 127   0   0   0\n",
       "                         K   1   1   8   0   0   0   2   5   0   0 121   0   0\n",
       "                         L   0   0   0   0   2   0   1   0   0   0   0 135   0\n",
       "                         M   1   0   1   0   0   0   1   1   0   0   0   0 137\n",
       "                         N   0   0   0   0   0   1   0   1   0   0   0   0   0\n",
       "                         O   0   0   1   1   0   0   1   2   0   1   1   0   0\n",
       "                         P   0   0   0   1   0   2   1   0   0   0   0   0   0\n",
       "                         Q   0   0   0   0   0   0   7   2   0   0   0   3   0\n",
       "                         R   1   5   0   0   1   0   2   7   0   0  10   0   0\n",
       "                         S   1   1   0   0   1   0   3   0   1   1   0   1   0\n",
       "                         T   0   0   0   0   2   2   0   0   0   0   1   0   0\n",
       "                         U   1   0   4   2   0   0   0   3   0   0   0   0   0\n",
       "                         V   0   0   0   0   0   0   2   4   0   0   0   0   0\n",
       "                         W   0   0   0   0   0   0   1   0   0   0   0   0   2\n",
       "                         X   0   1   0   0   2   0   0   2   2   0   2   4   0\n",
       "                         Y   3   0   0   0   0   1   0   1   0   0   0   0   0\n",
       "                         Z   2   0   0   0   1   0   0   0   2   4   0   0   0\n",
       "                          \n",
       "letter_predictions_polydot   N   O   P   Q   R   S   T   U   V   W   X   Y   Z\n",
       "                         A   1   2   0   6   0   1   1   1   0   1   0   0   1\n",
       "                         B   0   0   2   2   3   4   0   0   2   0   1   0   0\n",
       "                         C   0   1   0   1   0   0   0   0   0   0   0   0   0\n",
       "                         D   4   5   3   1   3   0   0   0   0   0   2   3   1\n",
       "                         E   0   0   0   3   0   9   1   0   0   0   2   0   4\n",
       "                         F   0   0  15   0   0   4   3   0   2   0   2   2   0\n",
       "                         G   0   1   3   8   1   4   2   1   0   0   2   0   0\n",
       "                         H   6  21   0   2   3   0   2   0   2   0   0   1   0\n",
       "                         I   0   0   1   0   0   3   0   0   0   0   5   1   1\n",
       "                         J   0   1   1   5   0   1   0   0   0   0   1   0   6\n",
       "                         K   2   0   1   0   7   0   1   2   0   0   7   0   0\n",
       "                         L   0   0   0   1   0   3   0   0   0   0   1   0   1\n",
       "                         M   3   0   0   0   0   0   0   3   0   8   0   1   0\n",
       "                         N 146   0   0   0   4   0   0   1   0   2   0   0   0\n",
       "                         O   1  98   2   3   1   0   0   4   0   0   0   0   0\n",
       "                         P   0   2 132   0   0   0   0   0   0   0   0   1   0\n",
       "                         Q   0   4   1 121   1   5   0   0   0   0   0   3   0\n",
       "                         R   1   1   1   0 137   0   1   0   1   0   0   0   0\n",
       "                         S   0   0   0  13   0 105   2   0   0   0   1   0   8\n",
       "                         T   0   0   0   0   0   2 133   1   0   0   1   2   2\n",
       "                         U   0   1   0   0   0   0   0 151   0   0   0   0   0\n",
       "                         V   2   1   1   2   1   0   0   0 126   2   0   3   0\n",
       "                         W   0   0   0   0   0   0   0   4   3 126   0   0   0\n",
       "                         X   0   1   0   0   0   2   0   0   0   0 134   1   0\n",
       "                         Y   0   0   5   0   0   0   3   0   0   0   0 127   0\n",
       "                         Z   0   0   0   0   0  18   2   0   0   0   0   0 134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "agreement_polydot\n",
       "FALSE  TRUE \n",
       "  632  3368 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letter_classifier_polydot <- ksvm(letter ~ ., data = letters_train, kernel = \"polydot\", C=3.5)\n",
    "letter_predictions_polydot <- predict(letter_classifier_polydot, letters_test)\n",
    "head(letter_predictions_polydot)\n",
    "\n",
    "table(letter_predictions_polydot, letters_test$letter)\n",
    "agreement_polydot <- letter_predictions_polydot == letters_test$letter\n",
    "table(agreement_polydot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when changing the C value the false predictions range from around 630 to 634 -> the polydot performs wy worse that the rbf network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Setting default kernel parameters  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>A</li>\n",
       "\t<li>W</li>\n",
       "\t<li>K</li>\n",
       "\t<li>L</li>\n",
       "\t<li>A</li>\n",
       "\t<li>F</li>\n",
       "</ol>\n",
       "\n",
       "<details>\n",
       "\t<summary style=display:list-item;cursor:pointer>\n",
       "\t\t<strong>Levels</strong>:\n",
       "\t</summary>\n",
       "\t<ol class=list-inline>\n",
       "\t\t<li>'A'</li>\n",
       "\t\t<li>'B'</li>\n",
       "\t\t<li>'C'</li>\n",
       "\t\t<li>'D'</li>\n",
       "\t\t<li>'E'</li>\n",
       "\t\t<li>'F'</li>\n",
       "\t\t<li>'G'</li>\n",
       "\t\t<li>'H'</li>\n",
       "\t\t<li>'I'</li>\n",
       "\t\t<li>'J'</li>\n",
       "\t\t<li>'K'</li>\n",
       "\t\t<li>'L'</li>\n",
       "\t\t<li>'M'</li>\n",
       "\t\t<li>'N'</li>\n",
       "\t\t<li>'O'</li>\n",
       "\t\t<li>'P'</li>\n",
       "\t\t<li>'Q'</li>\n",
       "\t\t<li>'R'</li>\n",
       "\t\t<li>'S'</li>\n",
       "\t\t<li>'T'</li>\n",
       "\t\t<li>'U'</li>\n",
       "\t\t<li>'V'</li>\n",
       "\t\t<li>'W'</li>\n",
       "\t\t<li>'X'</li>\n",
       "\t\t<li>'Y'</li>\n",
       "\t\t<li>'Z'</li>\n",
       "\t</ol>\n",
       "</details>"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item A\n",
       "\\item W\n",
       "\\item K\n",
       "\\item L\n",
       "\\item A\n",
       "\\item F\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\emph{Levels}: \\begin{enumerate*}\n",
       "\\item 'A'\n",
       "\\item 'B'\n",
       "\\item 'C'\n",
       "\\item 'D'\n",
       "\\item 'E'\n",
       "\\item 'F'\n",
       "\\item 'G'\n",
       "\\item 'H'\n",
       "\\item 'I'\n",
       "\\item 'J'\n",
       "\\item 'K'\n",
       "\\item 'L'\n",
       "\\item 'M'\n",
       "\\item 'N'\n",
       "\\item 'O'\n",
       "\\item 'P'\n",
       "\\item 'Q'\n",
       "\\item 'R'\n",
       "\\item 'S'\n",
       "\\item 'T'\n",
       "\\item 'U'\n",
       "\\item 'V'\n",
       "\\item 'W'\n",
       "\\item 'X'\n",
       "\\item 'Y'\n",
       "\\item 'Z'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. A\n",
       "2. W\n",
       "3. K\n",
       "4. L\n",
       "5. A\n",
       "6. F\n",
       "\n",
       "\n",
       "\n",
       "**Levels**: 1. 'A'\n",
       "2. 'B'\n",
       "3. 'C'\n",
       "4. 'D'\n",
       "5. 'E'\n",
       "6. 'F'\n",
       "7. 'G'\n",
       "8. 'H'\n",
       "9. 'I'\n",
       "10. 'J'\n",
       "11. 'K'\n",
       "12. 'L'\n",
       "13. 'M'\n",
       "14. 'N'\n",
       "15. 'O'\n",
       "16. 'P'\n",
       "17. 'Q'\n",
       "18. 'R'\n",
       "19. 'S'\n",
       "20. 'T'\n",
       "21. 'U'\n",
       "22. 'V'\n",
       "23. 'W'\n",
       "24. 'X'\n",
       "25. 'Y'\n",
       "26. 'Z'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] A W K L A F\n",
       "Levels: A B C D E F G H I J K L M N O P Q R S T U V W X Y Z"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "                          \n",
       "letter_predictions_tanhdot  A  B  C  D  E  F  G  H  I  J  K  L  M  N  O  P  Q\n",
       "                         A 32 28  2 27  5  3 17 41 79 55 30 51 39 25 31  7 41\n",
       "                         B  3 32  4 24 15  5 18 11  2  6 10 10  0  0 12  2 18\n",
       "                         C  0  0 22  0  3  0 14  0  2  9  2  1  0  0  1  0  1\n",
       "                         D  0  0  0 13  0  8  0  4  1  0  0  6  0  1  4  5  2\n",
       "                         E  0  0  2  0  0  0  0  0  1  0  2  0  0  0  0  0  0\n",
       "                         F  0  0  4  6  7 35  2  6 11  9  2  0  0  6  2 96  2\n",
       "                         G  0  7  5  0  2  3  5 14  0  0  2 18  0 10  4  1 16\n",
       "                         H 26  8  3 30  2  6  6  4  0  2  0  1 16 29 26  9 14\n",
       "                         I 30 18  0 19 10 16  2  1 15 38  1  8  1  1  1  6  0\n",
       "                         J 13  8  6  7 17  1  6  3  7  5  4 14  2  0  9  3  8\n",
       "                         K  4  0 28  0  8  9 24  2  1  3 10  7 14  3  0  1  1\n",
       "                         L 35  3 45 13 55  0 46 14 16  5 31 17  0  5 21  1 16\n",
       "                         M  0  2  0  1  0  0  0  1  2  0  7  0 11  6  0  0  0\n",
       "                         N  1  0  1  0  0  0  1  2  0  0  0  0 10 16  0  4  0\n",
       "                         O  1  1  0  9  0  0  1 25  0  2  7  6 30 19 19  2 15\n",
       "                         P  0  2  0  0  0  7  0  0  3  0  0  0  0  1  0  7  0\n",
       "                         Q  1  2  2  0  0  0  9  0  0  8  5  1  1  0  2  0  4\n",
       "                         R  0  6  0  0  0  0  0  3  1  0  3  0  0  0  0  2  1\n",
       "                         S  2 18  4  9 17  5  7  1  3  5  3  7  1  1  1  1 17\n",
       "                         T  3  0 10  2  5 34  0  8  3  0  3  0  0  4  1 10  1\n",
       "                         U  1  0  0  5  1  1  0  1  0  0  1  0 10  1  2  0  0\n",
       "                         V  4  0  3  0  0 15  0  8  0  0 17  0  4 24  1  8  8\n",
       "                         W  0  1  0  0  1  3  6  2  0  0  1  5  5 14  2  2  3\n",
       "                         X  0  0  0  1  2  0  0  0  8  0  5  4  0  0  0  0  0\n",
       "                         Y  0  0  0  0  0  2  0  0  0  0  0  1  0  0  0  1  0\n",
       "                         Z  0  0  1  1  2  0  0  0 10  1  0  0  0  0  0  0  0\n",
       "                          \n",
       "letter_predictions_tanhdot  R  S  T  U  V  W  X  Y  Z\n",
       "                         A 37 13  0  4  2  4 33  3  3\n",
       "                         B 41 16  2  0  1  1 14  0 19\n",
       "                         C  0  0  1  1  0  0  0  0  0\n",
       "                         D  1  2 11  0  0  0  1  0  3\n",
       "                         E  0  0  3  0  0  0  1  0  0\n",
       "                         F  5 18 39  7 34 16  8 31 18\n",
       "                         G  4  7  0  4  0  0  0  0  0\n",
       "                         H 12  4  0 18 11 14  0  4  0\n",
       "                         I 20 14 18  0  1  0 13 17 18\n",
       "                         J  2 19  2  0  0  0  8  0 18\n",
       "                         K  1  1  1  8 14  2  1  0  0\n",
       "                         L  7 28  2 13  0  0 39  1 39\n",
       "                         M  7  0  1  3  1  3  0  0  0\n",
       "                         N  1  0  0  8  9 36  0  8  0\n",
       "                         O  2  1  0 31  0  2  2  0  0\n",
       "                         P  0  0  6  0  3  1  1 14  0\n",
       "                         Q  7  9  0  0  0  2  0  3  4\n",
       "                         R  6  0  0  3  0  2  1  0  0\n",
       "                         S  3 21  8  0  0  0 16 10 30\n",
       "                         T  0  1 20 35 20  1 10 16  4\n",
       "                         U  0  0  1 12 13 13  1  2  0\n",
       "                         V  0  4 26 17 22 39  4 22  0\n",
       "                         W  3  0  1  1  1  1  0  5  0\n",
       "                         X  2  0  6  0  0  0  4  8  1\n",
       "                         Y  0  0  2  2  4  2  0  1  0\n",
       "                         Z  0  3  1  1  0  0  2  0  1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "agreement_tanhdot\n",
       "FALSE  TRUE \n",
       " 3665   335 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "letter_classifier_tanhdot <- ksvm(letter ~ ., data = letters_train, kernel = \"tanhdot\", C=5)\n",
    "letter_predictions_tanhdot <- predict(letter_classifier_tanhdot, letters_test)\n",
    "head(letter_predictions_tanhdot)\n",
    "\n",
    "table(letter_predictions_tanhdot, letters_test$letter)\n",
    "agreement_tanhdot <- letter_predictions_tanhdot == letters_test$letter\n",
    "table(agreement_tanhdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, tanhdot takes a reeeeeeeally long time for my poor thinkpad X220 <3 to compute.\n",
    "\n",
    "Performance was ridiculous in comparison to the other tests. 3654 wrong predictions with a C value of 0.5.\n",
    "\n",
    "Second run with a C value of 1 the error was even higher with 3662 wrong predictions.\n",
    "\n",
    "Next up C=5: 3665 false predictions. time to move on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fifth Exercise: Meta learning in R, Exercise Bagging 22.05.2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1000 obs. of  17 variables:\n",
      " $ checking_balance    : Factor w/ 4 levels \"< 0 DM\",\"> 200 DM\",..: 1 3 4 1 1 4 4 3 4 3 ...\n",
      " $ months_loan_duration: int  6 48 12 42 24 36 24 36 12 30 ...\n",
      " $ credit_history      : Factor w/ 5 levels \"critical\",\"good\",..: 1 2 1 2 4 2 2 2 2 1 ...\n",
      " $ purpose             : Factor w/ 6 levels \"business\",\"car\",..: 5 5 4 5 2 4 5 2 5 2 ...\n",
      " $ amount              : int  1169 5951 2096 7882 4870 9055 2835 6948 3059 5234 ...\n",
      " $ savings_balance     : Factor w/ 5 levels \"< 100 DM\",\"> 1000 DM\",..: 5 1 1 1 1 5 4 1 2 1 ...\n",
      " $ employment_duration : Factor w/ 5 levels \"< 1 year\",\"> 7 years\",..: 2 3 4 4 3 3 2 3 4 5 ...\n",
      " $ percent_of_income   : int  4 2 2 2 3 2 3 2 2 4 ...\n",
      " $ years_at_residence  : int  4 2 3 4 4 4 4 2 4 2 ...\n",
      " $ age                 : int  67 22 49 45 53 35 53 35 61 28 ...\n",
      " $ other_credit        : Factor w/ 3 levels \"bank\",\"none\",..: 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ housing             : Factor w/ 3 levels \"other\",\"own\",..: 2 2 2 1 1 1 2 3 2 2 ...\n",
      " $ existing_loans_count: int  2 1 1 1 2 1 1 1 1 2 ...\n",
      " $ job                 : Factor w/ 4 levels \"management\",\"skilled\",..: 2 2 4 2 2 4 2 1 4 1 ...\n",
      " $ dependents          : int  1 1 2 2 2 2 1 1 1 1 ...\n",
      " $ phone               : Factor w/ 2 levels \"no\",\"yes\": 2 1 1 1 1 2 1 2 1 1 ...\n",
      " $ default             : Factor w/ 2 levels \"no\",\"yes\": 1 2 1 1 2 1 1 1 1 2 ...\n"
     ]
    }
   ],
   "source": [
    "credit <- read.csv(\"credit.csv\")\n",
    "str(credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Assignment 1 Describe database\n",
    "\n",
    "1000 Objects, 17 variables. Numerical values and also character strings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"table(credit$checking_balance)\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "    < 0 DM   > 200 DM 1 - 200 DM    unknown \n",
       "       274         63        269        394 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"-----------------------------\"\n",
      "[1] \"table(credit$savings_balance)\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "     < 100 DM     > 1000 DM  100 - 500 DM 500 - 1000 DM       unknown \n",
       "          603            48           103            63           183 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"-----------------------------\"\n",
      "[1] \"summary(credit$months_loan_duration)\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  4.000  12.000  18.000  20.903  24.000  72.000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"-----------------------------\"\n",
      "[1] \"summary(credit$amount)\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n",
       "  250.000  1365.500  2319.500  3271.258  3972.250 18424.000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"table(credit$checking_balance)\")\n",
    "table(credit$checking_balance)\n",
    "print(\"-----------------------------\")\n",
    "print(\"table(credit$savings_balance)\")\n",
    "table(credit$savings_balance)\n",
    "print(\"-----------------------------\")\n",
    "print(\"summary(credit$months_loan_duration)\")\n",
    "summary(credit$months_loan_duration)\n",
    "print(\"-----------------------------\")\n",
    "print(\"summary(credit$amount)\")\n",
    "summary(credit$amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2 \n",
    "\n",
    "The output shows the distribution of checking balances, savings balances, and measures of location like min, max, several quantiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           \n",
       "credit_pred  no yes\n",
       "        no  699   2\n",
       "        yes   1 298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Bagged CART \n",
       "\n",
       "1000 samples\n",
       "  16 predictor\n",
       "   2 classes: 'no', 'yes' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 900, 900, 900, 900, 900, 900, ... \n",
       "Resampling results:\n",
       "\n",
       "  Accuracy  Kappa       \n",
       "  0.746     0.3540389261\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ipred)\n",
    "\n",
    "set.seed(300)\n",
    "mybag <- bagging(default ~ ., data = credit, nbagg = 25)\n",
    "credit_pred <- predict(mybag, credit)\n",
    "table(credit_pred, credit$default)\n",
    "\n",
    "library(caret) # install it first using install.packages(\"caret\") \n",
    "#I also needed to install the \"gcc-fortran\" package for my arch linux installation, might be \"gfortran\" in debian based distros\n",
    "\n",
    "set.seed(300)\n",
    "ctrl <- trainControl(method = \"cv\", number = 10)\n",
    "train(default ~ ., data = credit, method = \"treebag\", trControl = ctrl) #first time package \"e1071\" was missing so i installed that in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3: Explain last code and output\n",
    "\n",
    "Prediction works quite good with only 3 wrong predicitons.\n",
    "The 1000 samples resulted in 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(svmBag)\n",
    "svmBag$fit\n",
    "bagctrl <- bagControl(fit = svmBag$fit, predict = svmBag$pred, aggregate = svmBag$aggregate)\n",
    "set.seed(300)\n",
    "# training does not work and produces a bunch of errors I could not get to go away\n",
    "#svmbag <- train(default ~ ., data = credit, \"bag\", trControl = ctrl, bagControl = bagctrl)\n",
    "#svmbag\n",
    "# for further research: https://cran.r-project.org/web/packages/caret/caret.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4\n",
    "\n",
    "Did not train without error -> no result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05.06.2018 TicTacToe\n",
    "\n",
    "Image preprocessing:\n",
    "imager autocrop: https://www.rdocumentation.org/packages/imager/versions/0.41.1/topics/autocrop\n",
    "\n",
    "magick transform with threshold for straightening: \n",
    "\n",
    "https://www.rdocumentation.org/packages/magick/versions/1.9/topics/transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQY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\nTpiaiUKn0uVkqO+Xk4DZeG6LBiF5a0WFyIgF7DchCFB//9k="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "# A tibble: 1 x 7\n",
       "  format width height colorspace matte filesize density\n",
       "  <chr>  <int>  <int> <chr>      <lgl>    <int> <chr>  \n",
       "1 JPEG     100    100 sRGB       TRUE         0 +72x+72"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"0 x 0\"\n",
      "[1] \"0 x 100\"\n",
      "[1] \"0 x 200\"\n",
      "[1] \"100 x 0\"\n",
      "[1] \"100 x 100\"\n",
      "[1] \"100 x 200\"\n",
      "[1] \"200 x 0\"\n",
      "[1] \"200 x 100\"\n",
      "[1] \"200 x 200\"\n",
      "X\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "FALSE"
      ],
      "text/latex": [
       "FALSE"
      ],
      "text/markdown": [
       "FALSE"
      ],
      "text/plain": [
       "[1] FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>3</li>\n",
       "\t<li>5</li>\n",
       "\t<li>9</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 3\n",
       "\\item 5\n",
       "\\item 9\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 3\n",
       "3. 5\n",
       "4. 9\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1 3 5 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(magick)\n",
    "library(tesseract)\n",
    "im <- image_read(\"ttt8.jpeg\")\n",
    "\n",
    "#library(magrittr)\n",
    "#library(imager)\n",
    "\n",
    "#autocrop(im, color = color.at(im, 20, 20), axes = \"yx\")\n",
    "\n",
    "im <- image_trim(im, fuzz=20)\n",
    "im <- image_resize(im, \"300x300!\")\n",
    "im <- image_contrast(im)\n",
    "im <- image_contrast(im)\n",
    "im <- image_transparent(im, \"black\", fuzz=30)\n",
    "im <- image_crop(im, \"100x100+10\")\n",
    "im\n",
    "\n",
    "height <- 0\n",
    "width <- 0\n",
    "\n",
    "l <- c()\n",
    "#cat(l)\n",
    "\n",
    "while ( height<=200) {\n",
    "    #cat(\"H: \",height,\"\\n\")\n",
    "    while (width<=200) {\n",
    "        #cat(\"W: \",width,\"\\n\")\n",
    "        cropstr <- capture.output(cat(height,\"x\",width))\n",
    "        print(cropstr)\n",
    "        im <- image_crop(im, cropstr)\n",
    "        #print(im)\n",
    "        l<-c(l,im)\n",
    "        width=width+100\n",
    "        \n",
    "    }\n",
    "    height=height+100\n",
    "    width=0\n",
    "}\n",
    "\n",
    "cat(image_ocr(im))\n",
    "\n",
    "result_v <- vector(,9)\n",
    "\n",
    "\n",
    "prepare_for_O <- function(ocr_sample_input) {\n",
    " replacements_O <- c(\"o\", \"0\", \"g\", \"G\", \"ö\", \"Ö\", \"C\", \"c\", \"q\", \"Q\")\n",
    " \n",
    "    didReplace <- FALSE\n",
    "    \n",
    " updated_set_O <- c() \n",
    " for (input in ocr_sample_input) {\n",
    "  for (r_O in replacements_O) {\n",
    "   if (input == r_O) {\n",
    "    updated_set_O <- c(updated_set_O, \"O\")\n",
    "       didReplace  <- TRUE\n",
    "       break\n",
    "   }\n",
    "  }\n",
    "     if (!didReplace) {\n",
    "         updated_set_O <- c(updated_set_O, input)\n",
    "     }\n",
    "     didReplace <- FALSE\n",
    " }\n",
    " return(updated_set_O)\n",
    "}\n",
    "\n",
    "ocr_sample_input = c(\"X\", \"O\", \"X\", \"O\", \"X\", \"c\", \"G\", \"C\", \"M\")\n",
    "\n",
    "prepare_for_X <- function(ocr_sample_input) {\n",
    " replacements_X <- c(\"x\", \"X\", \"m\", \"M\" ,\"k\", \"K\", \"z\", \"Z\")\n",
    " \n",
    "    didReplace <- FALSE\n",
    "    \n",
    " updated_set_X <- c() \n",
    " for (input in ocr_sample_input) {\n",
    "  for (r_X in replacements_X) {\n",
    "   if (input == r_X) {\n",
    "    updated_set_X <- c(updated_set_X, \"X\")\n",
    "       didReplace  <- TRUE\n",
    "       break\n",
    "   }\n",
    "  }\n",
    "     if (!didReplace) {\n",
    "         updated_set_X <- c(updated_set_X, input)\n",
    "     }\n",
    "     didReplace <- FALSE\n",
    " }\n",
    " return(updated_set_X)\n",
    "}\n",
    "\n",
    "\n",
    "positions <- prepare_for_X(prepare_for_O(ocr_sample_input))\n",
    "\n",
    "comparedata <- c(c(1,2,3),c(4,5,6),c(7,8,9),c(1,4,7),c(2,5,8),c(3,6,9),c(1,5,4),c(3,5,7))\n",
    "\n",
    "\n",
    "indicesFor <- function(val, inputArray) {\n",
    " indices <- c()\n",
    "\n",
    " index <- 1\n",
    "\n",
    "for (input in inputArray) {\n",
    "  if (input == val) {\n",
    "    indices <- c(indices, index)\n",
    "  }\n",
    "   index <- index + 1\n",
    "  }\n",
    "return(indices)\n",
    "}\n",
    "\n",
    "x_positions <- indicesFor(\"X\", positions)\n",
    "\n",
    "comparedata[6][1] %in% x_positions\n",
    "#right[1] %in% x_positions\n",
    "\n",
    "x_positions\n",
    "\n",
    "for (right in comparedata){\n",
    "    result1 <- right[1] %in% x_positions\n",
    "    result2 <- right[2] %in% x_positions\n",
    "    result3 <- right[3] %in% x_positions\n",
    "    #print(right[1] %in% x_positions)\n",
    "    #print(result1 & result2)\n",
    "    if(result1 & result2 & result3){\n",
    "        print(\"\\n\\n\\nyay\\n\\n\\n\")\n",
    "        #print(right)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "#for (tile in )\n",
    "\n",
    "#cat(image_ocr(im2))\n",
    "#image_deskew(im2, threshold = 40)\n",
    "#tesseract::ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unfinished..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the learning journal\n",
    "\n",
    "I had to adapt the underlying latex template thats used for exporting the notebook to pdf.\n",
    "\n",
    "The resource I used for that was this url: http://www.markus-beuckelmann.de/blog/customizing-nbconvert-pdf.html\n",
    "\n",
    "Basically the code input and output cells were not wrapped at all so a wrapping function needed to be added.\n",
    "\n",
    "This worked better:\n",
    "http://compbio.ucsd.edu/outputting-beautiful-jupyter-notebooks-r-kernel-edition/\n",
    "\n",
    "Another solution to export the learning journal from jupyterlab was to export as html and then print it to pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying for the exam.\n",
    "\n",
    "Main focus for the exam was for me to get over the back propagation algorithm. Besides the slides I heavily relied on youtube videos to understand the principles behind it.\n",
    "\n",
    "Backpropagation explained by youtube channel \"Siraj Raval\":\n",
    "https://www.youtube.com/watch?v=FaHHWdsIYQg\n",
    "\n",
    "Backpropagation in 5 minutes by youtube channel \"Siraj Raval\"\n",
    "https://www.youtube.com/watch?v=q555kfIFUCM\n",
    "\n",
    "But the most understanding and best in depth explanation to get my brain started to grasp all the reasons was this youtube series by youtube channel \"3blue1brown\":\n",
    "Deep learning, chapter 1 to 4.\n",
    "\n",
    "https://www.youtube.com/watch?v=aircAruvnKk&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi\n",
    "\n",
    "Especially the reason for the gradient descent is greatly visualized and also the way data is transformed and used in training of a neural network.\n",
    "\n",
    "It was an important resource to get me started on"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
