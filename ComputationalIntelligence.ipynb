{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lection 1 - 08. Mar. 2018\n",
    "## 1.1. Evolutionary Computation\n",
    "\n",
    "What is evolutionary computing:\n",
    "https://en.wikipedia.org/wiki/Evolutionary_computation\n",
    "\n",
    "Confidence -> p. values, C-Intervals\n",
    "\n",
    "Computational intelligence emerged out of big data.\n",
    "\n",
    "Heuristic algorithm: cant always give solution, if solution you dont know if it is useable or correct\n",
    "\n",
    "Computational Intelligence vs AI:\n",
    "\n",
    "Both fall under maschine learning\n",
    "\n",
    "AI -> hard computing -> always the same algorithm -> like a monkey \n",
    "CI -> soft computing (soft boundaries, fuzzy logic(next semester)) -> very adaptive -> more complex -> makes it heuristic\n",
    "\n",
    "Clinical Trial, Beta Roll out, tweaking, market.\n",
    "\n",
    "Patient in the ICU -> artificial breathing -> wening (research that) -> liung machine gradually needs to lower its power so the lungs start breathing themselves again.\n",
    "\n",
    "MYCT->Processsor Speed\n",
    "\n",
    "## 1. Styles of learning\n",
    "\n",
    "Classification:\n",
    "100 records, 80 records used to trained the classifier ()training set, this classifier is tested against the remaining 20 (test set).\n",
    "\n",
    "\n",
    "Association:\n",
    "combining classifiers\n",
    "\n",
    "Clustering:\n",
    "\n",
    "\n",
    "\n",
    "## Attributes\n",
    "\n",
    "\n",
    "\n",
    "## I/O Problems\n",
    "\n",
    "Choose Appropriate architectures -> disadvantages: you dont know if the other algo would have worked\n",
    "\n",
    "Convert input -> disadvantages: accuracy of data gets lost and conversion rules need to be made\n",
    "\n",
    "\n",
    "## Conversion\n",
    "\n",
    "Hamming Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Execrise:\n",
    "\n",
    "I decided to use Jupyter Lab which is a self hosted development web ui for scientific note taking and data visualization. It is based on the open source project jupyter notebook also known as ipython shell.\n",
    "\n",
    "Besides python it supports multiple kernels which can be installed as you need them.\n",
    "\n",
    "For this learning journal I installed iRkernel to solve the R execises.\n",
    "\n",
    "Jupyter Lab feels like a traditional IDE with multiple configurable panels and splitable views.\n",
    "\n",
    "You have a file tree on the left, the main code panel for the notebook on the right. The Notebook itself consists of cells which can also have different kernels active. This enables to use Markdown in one cell and R in the next one. Markdown and raw text interpretation are shipped by default.\n",
    "\n",
    "https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html\n",
    "\n",
    "\n",
    "After installing Jupyter Lab and trying the first execise with rweka i had to run ```sudo R CMD javareconf``` and add some jvm shared libraries to the `LD_LIBRARY_PATH`\n",
    "\n",
    "This might also only have been necessary because the linux distribution I am running.\n",
    "\n",
    "--------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t8124 obs. of  23 variables:\n",
      " $ type                    : Factor w/ 2 levels \"edible\",\"poisonous\": 2 1 1 2 1 1 1 1 2 1 ...\n",
      " $ cap_shape               : Factor w/ 6 levels \"bell\",\"conical\",..: 3 3 1 3 3 3 1 1 3 1 ...\n",
      " $ cap_surface             : Factor w/ 4 levels \"fibrous\",\"grooves\",..: 4 4 4 3 4 3 4 3 3 4 ...\n",
      " $ cap_color               : Factor w/ 10 levels \"brown\",\"buff\",..: 1 10 9 9 4 10 9 9 9 10 ...\n",
      " $ bruises                 : Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 1 2 2 2 2 2 ...\n",
      " $ odor                    : Factor w/ 9 levels \"almond\",\"anise\",..: 8 1 2 8 7 1 1 2 8 1 ...\n",
      " $ gill_attachment         : Factor w/ 2 levels \"attached\",\"free\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ gill_spacing            : Factor w/ 2 levels \"close\",\"crowded\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " $ gill_size               : Factor w/ 2 levels \"broad\",\"narrow\": 2 1 1 2 1 1 1 1 2 1 ...\n",
      " $ gill_color              : Factor w/ 12 levels \"black\",\"brown\",..: 1 1 2 2 1 2 5 2 8 5 ...\n",
      " $ stalk_shape             : Factor w/ 2 levels \"enlarging\",\"tapering\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " $ stalk_root              : Factor w/ 5 levels \"bulbous\",\"club\",..: 3 2 2 3 3 2 2 2 3 2 ...\n",
      " $ stalk_surface_above_ring: Factor w/ 4 levels \"fibrous\",\"scaly\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " $ stalk_surface_below_ring: Factor w/ 4 levels \"fibrous\",\"scaly\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " $ stalk_color_above_ring  : Factor w/ 9 levels \"brown\",\"buff\",..: 8 8 8 8 8 8 8 8 8 8 ...\n",
      " $ stalk_color_below_ring  : Factor w/ 9 levels \"brown\",\"buff\",..: 8 8 8 8 8 8 8 8 8 8 ...\n",
      " $ veil_type               : Factor w/ 1 level \"partial\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ veil_color              : Factor w/ 4 levels \"brown\",\"orange\",..: 3 3 3 3 3 3 3 3 3 3 ...\n",
      " $ ring_number             : Factor w/ 3 levels \"none\",\"one\",\"two\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " $ ring_type               : Factor w/ 5 levels \"evanescent\",\"flaring\",..: 5 5 5 5 1 5 5 5 5 5 ...\n",
      " $ spore_print_color       : Factor w/ 9 levels \"black\",\"brown\",..: 1 2 2 1 2 1 1 2 1 1 ...\n",
      " $ population              : Factor w/ 6 levels \"abundant\",\"clustered\",..: 4 3 3 4 1 3 3 4 5 4 ...\n",
      " $ habitat                 : Factor w/ 7 levels \"grasses\",\"leaves\",..: 5 1 3 5 1 1 3 3 1 3 ...\n"
     ]
    }
   ],
   "source": [
    "#install.packages(\"RWeka\")\n",
    "\n",
    "library(RWeka)\n",
    "\n",
    "#Assignment 1\n",
    "mushrooms <- read.csv(\"mushrooms.csv\", stringsAsFactors = TRUE)\n",
    "\n",
    "str(mushrooms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1:\n",
    "\n",
    "### Take a look at the database, and describe it in your learning journal\n",
    "\n",
    "Dataset has 23 variables with 2-12 levels. \n",
    "\n",
    "The variables describe the appearance and behaviour of the mushrooms. \n",
    "\n",
    "\"Type\" for example has to levels -> edible and poisonous while cap color is much more granulous with 10 distinguished colors for the cap of the mushroom.\n",
    "\n",
    "The variables describe the appearance, behaviour, odor, spatial distribution and so on.\n",
    "\n",
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2\n",
    "\n",
    "### use the str() command on all 23 variables. Do you notice anything unusual?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Factor w/ 2 levels \"edible\",\"poisonous\": 2 1 1 2 1 1 1 1 2 1 ...\n",
      " Factor w/ 6 levels \"bell\",\"conical\",..: 3 3 1 3 3 3 1 1 3 1 ...\n",
      " Factor w/ 4 levels \"fibrous\",\"grooves\",..: 4 4 4 3 4 3 4 3 3 4 ...\n",
      " Factor w/ 10 levels \"brown\",\"buff\",..: 1 10 9 9 4 10 9 9 9 10 ...\n",
      " Factor w/ 2 levels \"no\",\"yes\": 2 2 2 2 1 2 2 2 2 2 ...\n",
      " Factor w/ 9 levels \"almond\",\"anise\",..: 8 1 2 8 7 1 1 2 8 1 ...\n",
      " Factor w/ 2 levels \"attached\",\"free\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " Factor w/ 2 levels \"close\",\"crowded\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " Factor w/ 2 levels \"broad\",\"narrow\": 2 1 1 2 1 1 1 1 2 1 ...\n",
      " Factor w/ 12 levels \"black\",\"brown\",..: 1 1 2 2 1 2 5 2 8 5 ...\n",
      " Factor w/ 2 levels \"enlarging\",\"tapering\": 1 1 1 1 2 1 1 1 1 1 ...\n",
      " Factor w/ 5 levels \"bulbous\",\"club\",..: 3 2 2 3 3 2 2 2 3 2 ...\n",
      " Factor w/ 4 levels \"fibrous\",\"scaly\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " Factor w/ 4 levels \"fibrous\",\"scaly\",..: 4 4 4 4 4 4 4 4 4 4 ...\n",
      " Factor w/ 9 levels \"brown\",\"buff\",..: 8 8 8 8 8 8 8 8 8 8 ...\n",
      " Factor w/ 9 levels \"brown\",\"buff\",..: 8 8 8 8 8 8 8 8 8 8 ...\n",
      " Factor w/ 1 level \"partial\": 1 1 1 1 1 1 1 1 1 1 ...\n",
      " Factor w/ 4 levels \"brown\",\"orange\",..: 3 3 3 3 3 3 3 3 3 3 ...\n",
      " Factor w/ 3 levels \"none\",\"one\",\"two\": 2 2 2 2 2 2 2 2 2 2 ...\n",
      " Factor w/ 5 levels \"evanescent\",\"flaring\",..: 5 5 5 5 1 5 5 5 5 5 ...\n",
      " Factor w/ 9 levels \"black\",\"brown\",..: 1 2 2 1 2 1 1 2 1 1 ...\n",
      " Factor w/ 6 levels \"abundant\",\"clustered\",..: 4 3 3 4 1 3 3 4 5 4 ...\n",
      " Factor w/ 7 levels \"grasses\",\"leaves\",..: 5 1 3 5 1 1 3 3 1 3 ...\n"
     ]
    }
   ],
   "source": [
    "#Assignment 2\n",
    "for ( i in 1:length(mushrooms) ) {\n",
    "    str(mushrooms[[i]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the `str()` function on all the variables it shows that using `str()` on the dataframe it describes the dataframe itself displaying the object type, the total amount of objects, the variables. \n",
    "\n",
    "When using `str()` on all the variables separately it doesn't show the variable names anymore and only the content type and head of content. \n",
    "\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3\n",
    "###  Record the output and your analysis of the output in your learning journal. How does the classifier perform? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odor:\n",
       "\talmond\t-> edible\n",
       "\tanise\t-> edible\n",
       "\tcreosote\t-> poisonous\n",
       "\tfishy\t-> poisonous\n",
       "\tfoul\t-> poisonous\n",
       "\tmusty\t-> poisonous\n",
       "\tnone\t-> edible\n",
       "\tpungent\t-> poisonous\n",
       "\tspicy\t-> poisonous\n",
       "(8004/8124 instances correct)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Assignment 3\n",
    "mushroom_1r <- OneR(type~., data=mushrooms)\n",
    "mushroom_1r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier got 8004 out of 8124 instances correct. I think it performed quite well.\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4\n",
    "### Analyze the Summary and Confusion Matrix printouts. Are there any terms that you do not understand? Look these up in google, and record their meaning. \n",
    "\n",
    "### Also, give an interpretation of the confusion matrix. How did the classifier perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "=== Summary ===\n",
       "\n",
       "Correctly Classified Instances        8004               98.5229 %\n",
       "Incorrectly Classified Instances       120                1.4771 %\n",
       "Kappa statistic                          0.9704\n",
       "Mean absolute error                      0.0148\n",
       "Root mean squared error                  0.1215\n",
       "Relative absolute error                  2.958  %\n",
       "Root relative squared error             24.323  %\n",
       "Total Number of Instances             8124     \n",
       "\n",
       "=== Confusion Matrix ===\n",
       "\n",
       "    a    b   <-- classified as\n",
       " 4208    0 |    a = edible\n",
       "  120 3796 |    b = poisonous"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Assignment 4\n",
    "summary(mushroom_1r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "120 instances were classfied incorrectly as edible which is bad for the mushroom gatherer, he poisoned now :'(\n",
    "\n",
    "All poisonous instances have been correctly classified as poisonous.\n",
    "\n",
    "\n",
    "Unknown terms:\n",
    "\n",
    "- Kappa statistics: value to mesaure interrater agreement which describes the degree of agreement between to parties.\n",
    "\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASSIGNMENT 5: Analyze the Summary and Confusion Matrix printouts again. Did this classifier perform better? If yes, how so?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "JRIP rules:\n",
       "===========\n",
       "\n",
       "(odor = foul) => type=poisonous (2160.0/0.0)\n",
       "(gill_size = narrow) and (gill_color = buff) => type=poisonous (1152.0/0.0)\n",
       "(gill_size = narrow) and (odor = pungent) => type=poisonous (256.0/0.0)\n",
       "(odor = creosote) => type=poisonous (192.0/0.0)\n",
       "(spore_print_color = green) => type=poisonous (72.0/0.0)\n",
       "(stalk_surface_below_ring = scaly) and (stalk_surface_above_ring = silky) => type=poisonous (68.0/0.0)\n",
       "(habitat = leaves) and (gill_attachment = free) and (population = clustered) => type=poisonous (16.0/0.0)\n",
       " => type=edible (4208.0/0.0)\n",
       "\n",
       "Number of Rules : 8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "=== Summary ===\n",
       "\n",
       "Correctly Classified Instances        8124              100      %\n",
       "Incorrectly Classified Instances         0                0      %\n",
       "Kappa statistic                          1     \n",
       "Mean absolute error                      0     \n",
       "Root mean squared error                  0     \n",
       "Relative absolute error                  0      %\n",
       "Root relative squared error              0      %\n",
       "Total Number of Instances             8124     \n",
       "\n",
       "=== Confusion Matrix ===\n",
       "\n",
       "    a    b   <-- classified as\n",
       " 4208    0 |    a = edible\n",
       "    0 3916 |    b = poisonous"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mushroom_JRip <- JRip(type ~ ., data = mushrooms)\n",
    "mushroom_JRip\n",
    "summary(mushroom_JRip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using JRip all instances have been classified correctly.\n",
    "\n",
    "In the previously used OneR classifier poisonousness was determined by the different odors only.\n",
    "\n",
    "JRip determined more rules that not only described one condition, but also combinations of features in boolean expressions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Exercise\n",
    "\n",
    "## Neural networks in Healthcare\n",
    "\n",
    "\n",
    "### Predicting cancer outcomes from histology and genomics using convolutional networks\n",
    "#### http://www.pnas.org/content/115/13/E2970\n",
    "\n",
    "\n",
    "# TODO\n",
    "\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Exercise\n",
    "\n",
    "## Neural networks in R\n",
    "\n",
    "\n",
    "loaded the concrete.csv into variable using read.csv from library RWeka.\n",
    "\n",
    "look at it using str()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"describe structure of concrete and its variables using str()\"\n",
      "'data.frame':\t1030 obs. of  9 variables:\n",
      " $ cement      : num  141 169 250 266 155 ...\n",
      " $ slag        : num  212 42.2 0 114 183.4 ...\n",
      " $ ash         : num  0 124.3 95.7 0 0 ...\n",
      " $ water       : num  204 158 187 228 193 ...\n",
      " $ superplastic: num  0 10.8 5.5 0 9.1 0 0 6.4 0 9 ...\n",
      " $ coarseagg   : num  972 1081 957 932 1047 ...\n",
      " $ fineagg     : num  748 796 861 670 697 ...\n",
      " $ age         : int  28 14 28 28 28 90 7 56 28 28 ...\n",
      " $ strength    : num  29.9 23.5 29.2 45.9 18.3 ...\n",
      " num [1:1030] 141 169 250 266 155 ...\n",
      " num [1:1030] 212 42.2 0 114 183.4 ...\n",
      " num [1:1030] 0 124.3 95.7 0 0 ...\n",
      " num [1:1030] 204 158 187 228 193 ...\n",
      " num [1:1030] 0 10.8 5.5 0 9.1 0 0 6.4 0 9 ...\n",
      " num [1:1030] 972 1081 957 932 1047 ...\n",
      " num [1:1030] 748 796 861 670 697 ...\n",
      " int [1:1030] 28 14 28 28 28 90 7 56 28 28 ...\n",
      " num [1:1030] 29.9 23.5 29.2 45.9 18.3 ...\n"
     ]
    }
   ],
   "source": [
    "concrete <- read.csv(\"concrete.csv\")\n",
    "\n",
    "print(\"describe structure of concrete and its variables using str()\")\n",
    "str(concrete)\n",
    "for ( i in 1:length(concrete) ) {\n",
    "    str(concrete[[i]])\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ASSIGNMENT 1: Take a look at the database, and describe it in your learning journal. \n",
    "\n",
    "9 Variables, 1030 Objects, only numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Cement:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  102 108.3   116 122.6   132   133 \n",
       "    4     4     4     4     2     5 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Slag:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0   11 13.6   15 17.2 17.5 \n",
       " 471    4    5    5    1    1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Ash:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "   0 24.5   59   60   71 71.5 \n",
       " 566   15    1    1    1    1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Water:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "121.8 126.6   127 127.3 137.8   140 \n",
       "    5     5     1     1     5     1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Superplastic:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  0 1.7 1.9   2 2.2 2.5 \n",
       "379   4   1   1   1   2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Coarseagg:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  801 801.1 801.4   811   814 814.1 \n",
       "    4     1     1     2     1     1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"fineagg:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  594   605 611.8   612   613 613.2 \n",
       "   30     5     5     1    22     2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"age:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "  1   3   7  14  28  56 \n",
       "  2 134 126  62 425  91 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"strength:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "2.33 3.32 4.57 4.78 4.83  4.9 \n",
       "   1    1    1    1    1    1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Cement:\")\n",
    "head(table(concrete$cement))\n",
    "print(\"Slag:\")\n",
    "head(table(concrete$slag))\n",
    "print(\"Ash:\")\n",
    "head(table(concrete$ash))\n",
    "print(\"Water:\")\n",
    "head(table(concrete$water))\n",
    "print(\"Superplastic:\")\n",
    "head(table(concrete$superplastic))\n",
    "print(\"Coarseagg:\")\n",
    "head(table(concrete$coarseagg))\n",
    "print(\"fineagg:\")\n",
    "head(table(concrete$fineagg))\n",
    "print(\"age:\")\n",
    "head(table(concrete$age))\n",
    "print(\"strength:\")\n",
    "head(table(concrete$strength))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignemnt 2\n",
    "\n",
    "Problem here is that the values are not between one and 0, therefore not being normalized.\n",
    "In neural networks values are activated using activation functions like the very basic sigmoid function or the ReLU (Rectified Linear Unit) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       " 0.0000  0.2664  0.4001  0.4172  0.5457  1.0000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "   2.33   23.71   34.45   35.82   46.13   82.60 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"summary of concrete_train:\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     cement            slag              ash             water       \n",
       " Min.   :0.0000   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.:0.2055   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.3450  \n",
       " Median :0.3628   Median :0.05565   Median :0.0000   Median :0.5104  \n",
       " Mean   :0.4055   Mean   :0.20589   Mean   :0.2627   Mean   :0.4824  \n",
       " 3rd Qu.:0.5662   3rd Qu.:0.39733   3rd Qu.:0.5912   3rd Qu.:0.5679  \n",
       " Max.   :1.0000   Max.   :0.95186   Max.   :0.9995   Max.   :1.0000  \n",
       "  superplastic      coarseagg         fineagg            age         \n",
       " Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n",
       " 1st Qu.:0.0000   1st Qu.:0.3808   1st Qu.:0.3352   1st Qu.:0.03571  \n",
       " Median :0.1863   Median :0.4855   Median :0.4629   Median :0.07418  \n",
       " Mean   :0.1851   Mean   :0.5067   Mean   :0.4504   Mean   :0.12523  \n",
       " 3rd Qu.:0.3137   3rd Qu.:0.6657   3rd Qu.:0.5795   3rd Qu.:0.15110  \n",
       " Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.00000  \n",
       "    strength     \n",
       " Min.   :0.0000  \n",
       " 1st Qu.:0.2655  \n",
       " Median :0.3921  \n",
       " Mean   :0.4152  \n",
       " 3rd Qu.:0.5469  \n",
       " Max.   :0.9894  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"summary of concrete_test\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     cement             slag              ash             water       \n",
       " Min.   :0.01438   Min.   :0.00000   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.:0.22374   1st Qu.:0.00000   1st Qu.:0.0000   1st Qu.:0.3291  \n",
       " Median :0.42466   Median :0.06678   Median :0.0000   Median :0.4617  \n",
       " Mean   :0.41973   Mean   :0.20475   Mean   :0.2952   Mean   :0.4623  \n",
       " 3rd Qu.:0.58676   3rd Qu.:0.40122   3rd Qu.:0.5927   3rd Qu.:0.5607  \n",
       " Max.   :1.00000   Max.   :1.00000   Max.   :1.0000   Max.   :0.9177  \n",
       "  superplastic      coarseagg         fineagg            age         \n",
       " Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.00000  \n",
       " 1st Qu.:0.0000   1st Qu.:0.3674   1st Qu.:0.3588   1st Qu.:0.01648  \n",
       " Median :0.2422   Median :0.4826   Median :0.4681   Median :0.07418  \n",
       " Mean   :0.2156   Mean   :0.4790   Mean   :0.4510   Mean   :0.11509  \n",
       " 3rd Qu.:0.3261   3rd Qu.:0.6448   3rd Qu.:0.5725   3rd Qu.:0.07418  \n",
       " Max.   :1.0000   Max.   :0.9689   Max.   :1.0000   Max.   :1.00000  \n",
       "    strength      \n",
       " Min.   :0.03052  \n",
       " 1st Qu.:0.27084  \n",
       " Median :0.41074  \n",
       " Mean   :0.42329  \n",
       " 3rd Qu.:0.53258  \n",
       " Max.   :1.00000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize <- function(x) {\n",
    " return((x - min(x)) / (max(x) - min(x)))\n",
    "}\n",
    "\n",
    "concrete_norm <- as.data.frame(lapply(concrete, normalize))\n",
    "\n",
    "summary(concrete_norm$strength)\n",
    "summary(concrete$strength)\n",
    "\n",
    "concrete_train <- concrete_norm[1:773, ]\n",
    "concrete_test <- concrete_norm[774:1030, ]\n",
    "\n",
    "print(\"summary of concrete_train:\")\n",
    "summary(concrete_train)\n",
    "\n",
    "print(\"summary of concrete_test\")\n",
    "summary(concrete_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 Compare summary of training and test data sets\n",
    "In both data sets the minimal and maximal values are exactly or at least close to 0 and 1. whiche lets assume the data is quite evenly distributed.\n",
    "\n",
    "Also the other statistical key figures like 1st quartile, median, mean and 3rd quartile are similar.\n",
    "\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(neuralnet)\n",
    "\n",
    "concrete_model <- neuralnet(strength ~ cement + slag + ash + water +\n",
    "superplastic + coarseagg + fineagg + age, data = concrete_train)\n",
    "plot(concrete_model)\n",
    "#TODO plot not showing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4 describe the plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Neural Networks 10.04.2018\n",
    "\n",
    "research: Parametrisch\n",
    "\n",
    "Can we simulate the Human Brain Functions? SOFA Framework?\n",
    "\n",
    "Euclidean distance: w.t.h. ?\n",
    "\n",
    "### 11.04.2018\n",
    "\n",
    "Fixe Daten können als Bias Nodes verwendet werden (research that!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### two publications from pubmed\n",
    "\n",
    "What, medical background\n",
    "what method, what neural network\n",
    "compare both publications\n",
    "\n",
    "pubmed search string: artificial neural networks.\n",
    "\n",
    "found articles: \n",
    "#### Predicting cancer outcomes from histology and genomics using convolutional networks.\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/29531073\n",
    "\n",
    "#### Deep Learning for Drug Design: an Artificial Intelligence Paradigm for Drug Discovery in the Big Data Era.\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/29603063\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation 24.4.2018\n",
    "\n",
    "output is the squashing function\n",
    "\n",
    "How do I know what a squashing function is?\n",
    "for example do I know that f(x)=1/(1+e^x)\n",
    "\n",
    "dEtotal/dw7=dEtotal/douto2*douto2/dneto2*dneto2/dw7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR 03.05.2018\n",
    "\n",
    "# TODO ASSIGNMENT 1: Take a look at the database, and describe it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters <- read.csv(\"letterdata.csv\")\n",
    "head(letters)\n",
    "\n",
    "letters_train <- letters[1:16000, ]\n",
    "letters_test <- letters[16001:20000, ]\n",
    "\n",
    "#install.packages(\"kernlab\") #only needs to be installed once\n",
    "library(kernlab)\n",
    "\n",
    "letter_classifier <- ksvm(letter ~ ., data = letters_train, kernel = \"vanilladot\")\n",
    "\n",
    "letter_classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Assignment 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_predictions <- predict(letter_classifier, letters_test)\n",
    "head(letter_predictions)\n",
    "\n",
    "table(letter_predictions, letters_test$letter)\n",
    "agreement <- letter_predictions == letters_test$letter\n",
    "table(agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_classifier_rbf <- ksvm(letter ~ ., data = letters_train, kernel = \"rbfdot\")\n",
    "letter_predictions_rbf <- predict(letter_classifier_rbf, letters_test)\n",
    "head(letter_predictions_rbf)\n",
    "\n",
    "table(letter_predictions_rbf, letters_test$letter)\n",
    "agreement_rbf <- letter_predictions_rbf == letters_test$letter\n",
    "table(agreement_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_classifier_polydot <- ksvm(letter ~ ., data = letters_train, kernel = \"polydot\")\n",
    "letter_predictions_polydot <- predict(letter_classifier_polydot, letters_test)\n",
    "head(letter_predictions_polydot)\n",
    "\n",
    "table(letter_predictions_polydot, letters_test$letter)\n",
    "agreement_polydot <- letter_predictions_polydot == letters_test$letter\n",
    "table(agreement_polydot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_classifier_tanhdot <- ksvm(letter ~ ., data = letters_train, kernel = \"tanhdot\")\n",
    "letter_predictions_tanhdot <- predict(letter_classifier_tanhdot, letters_test)\n",
    "head(letter_predictions_tanhdot)\n",
    "\n",
    "table(letter_predictions_tanhdot, letters_test$letter)\n",
    "agreement_tanhdot <- letter_predictions_tanhdot == letters_test$letter\n",
    "table(agreement_tanhdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical mixture of experts\n",
    "\n",
    "4-6 Folien 5-10 min Präsentation\n",
    "\n",
    "Hierarchical mixture of experts: non-linear combination of individual outputs by a multiple gating nodes arranged in a hierarchical fashion. bis Mittwoch 23. Mai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Bagging 22.05.2018\n",
    "\n",
    "Assignment 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit <- read.csv(\"credit.csv\")\n",
    "#str(credit)\n",
    "table(credit$checking_balance) \n",
    "table(credit$savings_balance)\n",
    "summary(credit$months_loan_duration)\n",
    "summary(credit$amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 2 \n",
    "firstly I had to again install the ipred package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ipred)\n",
    "\n",
    "set.seed(300)\n",
    "mybag <- bagging(default ~ ., data = credit, nbagg = 25)\n",
    "credit_pred <- predict(mybag, credit)\n",
    "table(credit_pred, credit$default)\n",
    "\n",
    "library(caret) # install it first using install.packages(\"caret\") \n",
    "#I also needed to install the \"gcc-fortran\" package for my arch linux installation, might be \"gfortran\" in debian based distros\n",
    "\n",
    "set.seed(300)\n",
    "ctrl <- trainControl(method = \"cv\", number = 10)\n",
    "train(default ~ ., data = credit, method = \"treebag\", trControl = ctrl) #first time package \"e1071\" was missing so i installed that in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain last code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(svmBag)\n",
    "bagctrl <- bagControl(fit = svmBag$fit, predict = svmBag$pred, aggregate = svmBag$aggregate)\n",
    "set.seed(300)\n",
    "svmbag <- train(default ~ ., data = credit, \"bag\", trControl = ctrl, bagControl = bagctrl)\n",
    "svmbag\n",
    "# for further research: https://cran.r-project.org/web/packages/caret/caret.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.06.2018 TicTacToe\n",
    "\n",
    "Image preprocessing:\n",
    "imager autocrop: https://www.rdocumentation.org/packages/imager/versions/0.41.1/topics/autocrop\n",
    "\n",
    "magick transform with threshold for straightening: \n",
    "\n",
    "https://www.rdocumentation.org/packages/magick/versions/1.9/topics/transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "library(magick)\n",
    "library(tesseract)\n",
    "im <- image_read(\"ttt8.jpeg\")\n",
    "\n",
    "#library(magrittr)\n",
    "#library(imager)\n",
    "\n",
    "#autocrop(im, color = color.at(im, 20, 20), axes = \"yx\")\n",
    "\n",
    "im <- image_trim(im, fuzz=20)\n",
    "im <- image_resize(im, \"300x300!\")\n",
    "im <- image_contrast(im)\n",
    "im <- image_contrast(im)\n",
    "im <- image_transparent(im, \"black\", fuzz=30)\n",
    "im <- image_crop(im, \"100x100+10\")\n",
    "im\n",
    "\n",
    "height <- 0\n",
    "width <- 0\n",
    "\n",
    "l <- c()\n",
    "#cat(l)\n",
    "\n",
    "while ( height<=200) {\n",
    "    #cat(\"H: \",height,\"\\n\")\n",
    "    while (width<=200) {\n",
    "        #cat(\"W: \",width,\"\\n\")\n",
    "        cropstr <- capture.output(cat(height,\"x\",width))\n",
    "        print(cropstr)\n",
    "        im <- image_crop(im, cropstr)\n",
    "        #print(im)\n",
    "        l<-c(l,im)\n",
    "        width=width+100\n",
    "        \n",
    "    }\n",
    "    height=height+100\n",
    "    width=0\n",
    "}\n",
    "\n",
    "cat(image_ocr(im))\n",
    "\n",
    "result_v <- vector(,9)\n",
    "\n",
    "\n",
    "prepare_for_O <- function(ocr_sample_input) {\n",
    " replacements_O <- c(\"o\", \"0\", \"g\", \"G\", \"ö\", \"Ö\", \"C\", \"c\", \"q\", \"Q\")\n",
    " \n",
    "    didReplace <- FALSE\n",
    "    \n",
    " updated_set_O <- c() \n",
    " for (input in ocr_sample_input) {\n",
    "  for (r_O in replacements_O) {\n",
    "   if (input == r_O) {\n",
    "    updated_set_O <- c(updated_set_O, \"O\")\n",
    "       didReplace  <- TRUE\n",
    "       break\n",
    "   }\n",
    "  }\n",
    "     if (!didReplace) {\n",
    "         updated_set_O <- c(updated_set_O, input)\n",
    "     }\n",
    "     didReplace <- FALSE\n",
    " }\n",
    " return(updated_set_O)\n",
    "}\n",
    "\n",
    "ocr_sample_input = c(\"X\", \"O\", \"X\", \"O\", \"X\", \"c\", \"G\", \"C\", \"M\")\n",
    "\n",
    "prepare_for_X <- function(ocr_sample_input) {\n",
    " replacements_X <- c(\"x\", \"X\", \"m\", \"M\" ,\"k\", \"K\", \"z\", \"Z\")\n",
    " \n",
    "    didReplace <- FALSE\n",
    "    \n",
    " updated_set_X <- c() \n",
    " for (input in ocr_sample_input) {\n",
    "  for (r_X in replacements_X) {\n",
    "   if (input == r_X) {\n",
    "    updated_set_X <- c(updated_set_X, \"X\")\n",
    "       didReplace  <- TRUE\n",
    "       break\n",
    "   }\n",
    "  }\n",
    "     if (!didReplace) {\n",
    "         updated_set_X <- c(updated_set_X, input)\n",
    "     }\n",
    "     didReplace <- FALSE\n",
    " }\n",
    " return(updated_set_X)\n",
    "}\n",
    "\n",
    "\n",
    "positions <- prepare_for_X(prepare_for_O(ocr_sample_input))\n",
    "\n",
    "comparedata <- c(c(1,2,3),c(4,5,6),c(7,8,9),c(1,4,7),c(2,5,8),c(3,6,9),c(1,5,4),c(3,5,7))\n",
    "\n",
    "\n",
    "indicesFor <- function(val, inputArray) {\n",
    " indices <- c()\n",
    "\n",
    " index <- 1\n",
    "\n",
    "for (input in inputArray) {\n",
    "  if (input == val) {\n",
    "    indices <- c(indices, index)\n",
    "  }\n",
    "   index <- index + 1\n",
    "  }\n",
    "return(indices)\n",
    "}\n",
    "\n",
    "x_positions <- indicesFor(\"X\", positions)\n",
    "\n",
    "comparedata[6][1] %in% x_positions\n",
    "#right[1] %in% x_positions\n",
    "\n",
    "x_positions\n",
    "\n",
    "for (right in comparedata){\n",
    "    result1 <- right[1] %in% x_positions\n",
    "    result2 <- right[2] %in% x_positions\n",
    "    result3 <- right[3] %in% x_positions\n",
    "    #print(right[1] %in% x_positions)\n",
    "    #print(result1 & result2)\n",
    "    if(result1 & result2 & result3){\n",
    "        print(\"\\n\\n\\nyay\\n\\n\\n\")\n",
    "        #print(right)\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "#for (tile in )\n",
    "\n",
    "#cat(image_ocr(im2))\n",
    "#image_deskew(im2, threshold = 40)\n",
    "#tesseract::ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pürfungsrelevant\n",
    "Squashing functions\n",
    "What\n",
    "\n",
    "SVM (keine vectorrechnung)\n",
    "\n",
    "(Kein mathe bei radial bas** functions)\n",
    "\n",
    "Perceptron, Backwardpropagation\n",
    "\n",
    "OCR\n",
    "\n",
    "Bagging Boosting (eigene Präsentationen und die der Kollegen)\n",
    "\n",
    "Nichts zum Tic Tac Toe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the learning journal\n",
    "\n",
    "I had to adapt the underlying latex template thats used for exporting the notebook to pdf.\n",
    "\n",
    "The resource I used for that was this url: http://www.markus-beuckelmann.de/blog/customizing-nbconvert-pdf.html\n",
    "\n",
    "Basically the code input and output cells were not wrapped at all so a wrapping function needed to be added.\n",
    "\n",
    "This worked better:\n",
    "http://compbio.ucsd.edu/outputting-beautiful-jupyter-notebooks-r-kernel-edition/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
