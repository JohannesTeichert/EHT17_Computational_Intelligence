{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lection 1 - 08. Mar. 2018\n",
    "### Evolutionary Computation\n",
    "\n",
    "What is evolutionary computing:\n",
    "https://en.wikipedia.org/wiki/Evolutionary_computation\n",
    "\n",
    "Confidence -> p. values, C-Intervals\n",
    "\n",
    "Computational intelligence emerged out of big data.\n",
    "\n",
    "Heuristic algorithm: cant always give solution, if solution you dont know if it is useable or correct\n",
    "\n",
    "Computational Intelligence vs AI:\n",
    "\n",
    "Both fall under maschine learning\n",
    "\n",
    "AI -> hard computing -> always the same algorithm -> like a monkey \n",
    "CI -> soft computing (soft boundaries, fuzzy logic(next semester)) -> very adaptive -> more complex -> makes it heuristic\n",
    "\n",
    "Clinical Trial, Beta Roll out, tweaking, market.\n",
    "\n",
    "Patient in the ICU -> artificial breathing -> wening (research that) -> liung machine gradually needs to lower its power so the lungs start breathing themselves again.\n",
    "\n",
    "MYCT->Processsor Speed\n",
    "\n",
    "### Styles of learning\n",
    "\n",
    "Classification:\n",
    "100 records, 80 records used to trained the classifier ()training set, this classifier is tested against the remaining 20 (test set).\n",
    "\n",
    "\n",
    "Association:\n",
    "combining classifiers\n",
    "\n",
    "Clustering:\n",
    "\n",
    "\n",
    "\n",
    "### Attributes\n",
    "\n",
    "\n",
    "\n",
    "### I/O Problems\n",
    "\n",
    "Choose Appropriate architectures -> disadvantages: you dont know if the other algo would have worked\n",
    "\n",
    "Convert input -> disadvantages: accuracy of data gets lost and conversion rules need to be made\n",
    "\n",
    "\n",
    "### Conversion\n",
    "\n",
    "Hamming Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Execrise:\n",
    "\n",
    "Run sudo R CMD javareconf\n",
    "\n",
    "add path to LD_LIBRARY_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(\"RWeka\")\n",
    "\n",
    "library(RWeka)\n",
    "\n",
    "mushrooms <- read.csv(\"mushrooms.csv\", stringsAsFactors = TRUE)\n",
    "\n",
    "str(mushrooms)\n",
    "\n",
    "class(mushrooms)\n",
    "for (i in mushrooms){\n",
    "    print(\"start\")\n",
    "    str(i)\n",
    "    print(\"testestsetsetsetset\")\n",
    "    class(i)\n",
    "    print(\"testestsetsetsetset\")\n",
    "}\n",
    "table(mushrooms$type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biological Neural Networks 10.04.2018\n",
    "\n",
    "research: Parametrisch\n",
    "\n",
    "Can we simulate the Human Brain Functions? SOFA Framework?\n",
    "\n",
    "Euclidean distance: w.t.h. ?\n",
    "\n",
    "### 11.04.2018\n",
    "\n",
    "Fixe Daten können als Bias Nodes verwendet werden (research that!)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### two publications from pubmed\n",
    "\n",
    "What, medical background\n",
    "what method, what neural network\n",
    "compare both publications\n",
    "\n",
    "pubmed search string: artificial neural networks.\n",
    "\n",
    "found articles: \n",
    "#### Predicting cancer outcomes from histology and genomics using convolutional networks.\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/29531073\n",
    "\n",
    "#### Deep Learning for Drug Design: an Artificial Intelligence Paradigm for Drug Discovery in the Big Data Era.\n",
    "https://www.ncbi.nlm.nih.gov/pubmed/29603063\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 Neural Network in R 17.04.2018\n",
    "\n",
    "loaded the concrete.csv into variable using read.csv from library RWeka.\n",
    "\n",
    "look at it using str()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete <- read.csv(\"concrete.csv\")\n",
    "\n",
    "str(concrete)\n",
    "\n",
    "str(concrete$cement)\n",
    "str(concrete$slag)\n",
    "str(concrete$ash)\n",
    "str(concrete$water)\n",
    "str(concrete$superplastic)\n",
    "str(concrete$coarseagg)\n",
    "str(concrete$fineagg)\n",
    "str(concrete$age)\n",
    "str(concrete$strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation 24.4.2018\n",
    "\n",
    "output is the squashing function\n",
    "\n",
    "How do I know what a squashing function is?\n",
    "for example do I know that f(x)=1/(1+e^x)\n",
    "\n",
    "dEtotal/dw7=dEtotal/douto2*douto2/dneto2*dneto2/dw7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OCR 03.05.2018\n",
    "\n",
    "# TODO ASSIGNMENT 1: Take a look at the database, and describe it.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters <- read.csv(\"letterdata.csv\")\n",
    "head(letters)\n",
    "\n",
    "letters_train <- letters[1:16000, ]\n",
    "letters_test <- letters[16001:20000, ]\n",
    "\n",
    "#install.packages(\"kernlab\") #only needs to be installed once\n",
    "library(kernlab)\n",
    "\n",
    "letter_classifier <- ksvm(letter ~ ., data = letters_train, kernel = \"vanilladot\")\n",
    "\n",
    "letter_classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO Assignment 2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_predictions <- predict(letter_classifier, letters_test)\n",
    "head(letter_predictions)\n",
    "\n",
    "table(letter_predictions, letters_test$letter)\n",
    "agreement <- letter_predictions == letters_test$letter\n",
    "table(agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_classifier_rbf <- ksvm(letter ~ ., data = letters_train, kernel = \"rbfdot\")\n",
    "letter_predictions_rbf <- predict(letter_classifier_rbf, letters_test)\n",
    "head(letter_predictions_rbf)\n",
    "\n",
    "table(letter_predictions_rbf, letters_test$letter)\n",
    "agreement_rbf <- letter_predictions_rbf == letters_test$letter\n",
    "table(agreement_rbf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_classifier_polydot <- ksvm(letter ~ ., data = letters_train, kernel = \"polydot\")\n",
    "letter_predictions_polydot <- predict(letter_classifier_polydot, letters_test)\n",
    "head(letter_predictions_polydot)\n",
    "\n",
    "table(letter_predictions_polydot, letters_test$letter)\n",
    "agreement_polydot <- letter_predictions_polydot == letters_test$letter\n",
    "table(agreement_polydot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_classifier_tanhdot <- ksvm(letter ~ ., data = letters_train, kernel = \"tanhdot\")\n",
    "letter_predictions_tanhdot <- predict(letter_classifier_tanhdot, letters_test)\n",
    "head(letter_predictions_tanhdot)\n",
    "\n",
    "table(letter_predictions_tanhdot, letters_test$letter)\n",
    "agreement_tanhdot <- letter_predictions_tanhdot == letters_test$letter\n",
    "table(agreement_tanhdot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical mixture of experts\n",
    "\n",
    "4-6 Folien 5-10 min Präsentation\n",
    "\n",
    "Hierarchical mixture of experts: non-linear combination of individual outputs by a multiple gating nodes arranged in a hierarchical fashion. bis Mittwoch 23. Mai."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise Bagging 22.05.2018\n",
    "\n",
    "Assignment 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    < 0 DM   > 200 DM 1 - 200 DM    unknown \n",
       "       274         63        269        394 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "     < 100 DM     > 1000 DM  100 - 500 DM 500 - 1000 DM       unknown \n",
       "          603            48           103            63           183 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "    4.0    12.0    18.0    20.9    24.0    72.0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "    250    1366    2320    3271    3972   18424 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "credit <- read.csv(\"credit.csv\")\n",
    "#str(credit)\n",
    "table(credit$checking_balance) \n",
    "table(credit$savings_balance)\n",
    "summary(credit$months_loan_duration)\n",
    "summary(credit$amount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 2 \n",
    "firstly I had to again install the ipred package\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           \n",
       "credit_pred  no yes\n",
       "        no  699   2\n",
       "        yes   1 298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bagged CART \n",
       "\n",
       "1000 samples\n",
       "  16 predictor\n",
       "   2 classes: 'no', 'yes' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 900, 900, 900, 900, 900, 900, ... \n",
       "Resampling results:\n",
       "\n",
       "  Accuracy  Kappa    \n",
       "  0.746     0.3540389\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(ipred)\n",
    "\n",
    "set.seed(300)\n",
    "mybag <- bagging(default ~ ., data = credit, nbagg = 25)\n",
    "credit_pred <- predict(mybag, credit)\n",
    "table(credit_pred, credit$default)\n",
    "\n",
    "library(caret) # install it first using install.packages(\"caret\") \n",
    "#I also needed to install the \"gcc-fortran\" package for my arch linux installation, might be \"gfortran\" in debian based distros\n",
    "\n",
    "set.seed(300)\n",
    "ctrl <- trainControl(method = \"cv\", number = 10)\n",
    "train(default ~ ., data = credit, method = \"treebag\", trControl = ctrl) #first time package \"e1071\" was missing so i installed that in R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explain last code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 3\n",
      " $ fit      :function (x, y, ...)  \n",
      " $ pred     :function (object, x)  \n",
      " $ aggregate:function (x, type = \"class\")  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "“executing %dopar% sequentially: no parallel backend registered”Warning message:\n",
      "“model fit failed for Fold01: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold02: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold03: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold04: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold05: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold06: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold07: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold08: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold09: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message:\n",
      "“model fit failed for Fold10: vars=35 Error in fitter(btSamples[[iter]], x = x, y = y, ctrl = bagControl, v = vars,  : \n",
      "  task 1 failed - \"could not find function \"lev\"\"\n",
      "”Warning message in nominalTrainWorkflow(x = x, y = y, wts = weights, info = trainInfo, :\n",
      "“There were missing values in resampled performance measures.”"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Something is wrong; all the Accuracy metric values are missing:\n",
      "    Accuracy       Kappa    \n",
      " Min.   : NA   Min.   : NA  \n",
      " 1st Qu.: NA   1st Qu.: NA  \n",
      " Median : NA   Median : NA  \n",
      " Mean   :NaN   Mean   :NaN  \n",
      " 3rd Qu.: NA   3rd Qu.: NA  \n",
      " Max.   : NA   Max.   : NA  \n",
      " NA's   :1     NA's   :1    \n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error: Stopping\n",
     "execution_count": 3,
     "output_type": "error",
     "traceback": [
      "Error: Stopping\nTraceback:\n",
      "1. train(default ~ ., data = credit, \"bag\", trControl = ctrl, bagControl = bagctrl)",
      "2. train.formula(default ~ ., data = credit, \"bag\", trControl = ctrl, \n .     bagControl = bagctrl)",
      "3. train(x, y, weights = w, ...)",
      "4. train.default(x, y, weights = w, ...)",
      "5. stop(\"Stopping\", call. = FALSE)"
     ]
    }
   ],
   "source": [
    "str(svmBag)\n",
    "bagctrl <- bagControl(fit = svmBag$fit, predict = svmBag$pred, aggregate = svmBag$aggregate)\n",
    "set.seed(300)\n",
    "svmbag <- train(default ~ ., data = credit, \"bag\", trControl = ctrl, bagControl = bagctrl)\n",
    "svmbag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
